{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af24d0",
   "metadata": {},
   "source": [
    "## Exploraty Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "da38a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e082c735",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  i think i actually under-rate ok computer if a...     5.0\n",
       "1  i get why radiohead rub a lot of people the wr...     5.0\n",
       "2  i would like to think i am good about not lett...     4.5\n",
       "3  there are radiohead devotees like there were o...     4.0\n",
       "4  i wrote a shining excellent review for this al...     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/music_album_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 80271\n",
      "Rating distribution:\n",
      "Rating\n",
      "5.0    29534\n",
      "4.5    17793\n",
      "4.0    14213\n",
      "3.5     7048\n",
      "3.0     4430\n",
      "2.5     2210\n",
      "2.0     1396\n",
      "1.5      640\n",
      "1.0      525\n",
      "0.5      398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(f\"Rating distribution:\\n{df['Rating'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb8eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review      26\n",
       "Rating    2084\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f313865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6d4e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tokenizes the text,lowercase the text, remove stopwords, and lemmatize the text \n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)  # Keep !? for sentiment\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>think actually underrate ok computer anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>get radiohead rub lot people wrong way lot peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>would like think good letting wider critical w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>radiohead devotee like bowie devotee find unex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wrote shining excellent review album browser w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  \\\n",
       "0  i think i actually under-rate ok computer if a...     5.0   \n",
       "1  i get why radiohead rub a lot of people the wr...     5.0   \n",
       "2  i would like to think i am good about not lett...     4.5   \n",
       "3  there are radiohead devotees like there were o...     4.0   \n",
       "4  i wrote a shining excellent review for this al...     5.0   \n",
       "\n",
       "                                      Cleaned_Review  \n",
       "0  think actually underrate ok computer anything ...  \n",
       "1  get radiohead rub lot people wrong way lot peo...  \n",
       "2  would like think good letting wider critical w...  \n",
       "3  radiohead devotee like bowie devotee find unex...  \n",
       "4  wrote shining excellent review album browser w...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'] = df['Review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f5a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7734a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb80a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the empty strings in cleaned_review column\n",
    "df = df[df['Cleaned_Review'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0293cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f3af1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_csv \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/cleaned_music_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_csv = df.to_csv('./dataset/cleaned_music_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae85f3d2",
   "metadata": {},
   "source": [
    "## Loading Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6dc66420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review            0\n",
       "Rating            0\n",
       "Cleaned_Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/cleaned_music_reviews.csv')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db17da27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution of the cleaned dataset (before balancing):\n",
      "Rating\n",
      "5.0    29395\n",
      "4.5    17728\n",
      "4.0    14153\n",
      "3.5     7011\n",
      "3.0     4416\n",
      "2.5     2201\n",
      "2.0     1387\n",
      "1.5      634\n",
      "1.0      521\n",
      "0.5      395\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution after balancing (oversampling lower ratings):\n",
      "Rating\n",
      "5.0    29395\n",
      "4.5    29395\n",
      "4.0    29395\n",
      "2.5    29395\n",
      "2.0    29395\n",
      "3.0    29395\n",
      "1.5    29395\n",
      "3.5    29395\n",
      "0.5    29395\n",
      "1.0    29395\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Class distribution of the cleaned dataset (before balancing):\")\n",
    "print(data['Rating'].value_counts())\n",
    "\n",
    "# Handle class imbalance by oversampling reviews with lower ratings\n",
    "# Find the maximum class count\n",
    "max_count = data['Rating'].value_counts().max()\n",
    "\n",
    "# For each unique rating, resample to match the max_count\n",
    "from sklearn.utils import resample\n",
    "\n",
    "balanced_data = []\n",
    "for rating in data['Rating'].unique():\n",
    "    subset = data[data['Rating'] == rating]\n",
    "    if len(subset) < max_count:\n",
    "        # Oversample (with replacement) to match max_count\n",
    "        subset_upsampled = resample(subset, \n",
    "                                    replace=True, \n",
    "                                    n_samples=max_count, \n",
    "                                    random_state=42)\n",
    "        balanced_data.append(subset_upsampled)\n",
    "    else:\n",
    "        balanced_data.append(subset)\n",
    "\n",
    "# Concatenate all upsampled subsets\n",
    "data_balanced = pd.concat(balanced_data)\n",
    "\n",
    "print(\"\\nClass distribution after balancing (oversampling lower ratings):\")\n",
    "print(data_balanced['Rating'].value_counts())\n",
    "\n",
    "# Use data_balanced for further processing\n",
    "data = data_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f746fb22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rating\n",
       "5.0    29395\n",
       "4.5    29395\n",
       "4.0    29395\n",
       "2.5    29395\n",
       "2.0    29395\n",
       "3.0    29395\n",
       "1.5    29395\n",
       "3.5    29395\n",
       "0.5    29395\n",
       "1.0    29395\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_balanced['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3794acf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,3),\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    sublinear_tf=True \n",
    ")\n",
    "\n",
    "X2 = tfidf_vectorizer.fit_transform(data_balanced['Cleaned_Review'])\n",
    "vocab2 = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "97c8f4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = data_balanced['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "10c1dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5e106e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09264052681406838\n",
      "R2: 0.955095409038368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "model2 = Ridge(alpha=1.0)\n",
    "model2.fit(X_train_2,y_train_2)\n",
    "y_pred = model2.predict(X_test_2)\n",
    "\n",
    "mse = mean_squared_error(y_test_2,y_pred)\n",
    "r2 = r2_score(y_test_2,y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8804c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: The album was a masterpiece from start to finish\n",
      "Predicted rating: 5.00 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Some good tracks but overall disappointing\n",
      "Predicted rating: 3.02 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The vocals were amazing, though the production quality ruined it\n",
      "Predicted rating: 2.98 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Mediocre at best - nothing special\n",
      "Predicted rating: 1.87 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album changed my life! Perfect in every way\n",
      "Predicted rating: 5.00 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album was the worst thing I heard in my life, Death to the artist and the producer, disgusting, awful, bad , waste of time\n",
      "Predicted rating: 1.50 (scale: 0.5-5.0)\n",
      "\n",
      "Review: A genre-defying record that blends jazz, electronica, and rock seamlessly, though some tracks feel unnecessarily long and meandering.\n",
      "Predicted rating: 3.33 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Despite the hype, the album lacks originality and feels like a rehash of the band's previous work, with only a few standout moments.\n",
      "Predicted rating: 2.50 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The production is lush and detailed, but the lyrics are pretentious and the melodies forgettable, making for a frustrating listen.\n",
      "Predicted rating: 2.04 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Absolutely terrible album, not a single redeeming quality. I regret listening to it.\n",
      "Predicted rating: 2.25 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Horrible in every way, the worst music I've ever heard.\n",
      "Predicted rating: 2.94 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Unbearable noise, couldn't finish a single track.\n",
      "Predicted rating: 3.38 (scale: 0.5-5.0)\n",
      "\n",
      "Review: A complete disaster, avoid at all costs.\n",
      "Predicted rating: 2.04 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Painful to listen to, a total waste of time.\n",
      "Predicted rating: 2.59 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Zero talent, zero effort, zero enjoyment.\n",
      "Predicted rating: 2.52 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album is an insult to music.\n",
      "Predicted rating: 4.56 (scale: 0.5-5.0)\n",
      "\n",
      "Review: If I could give it a zero, I would.\n",
      "Predicted rating: 2.60 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The most disappointing and awful release of the year.\n",
      "Predicted rating: 1.19 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Disgusting, offensive, and unlistenable.\n",
      "Predicted rating: 1.98 (scale: 0.5-5.0)\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(review):\n",
    "    # Preprocess\n",
    "    processed_review = preprocess_text(review)\n",
    "\n",
    "    # Transform\n",
    "    review_vector = tfidf_vectorizer.transform([processed_review])\n",
    "\n",
    "    # Predict\n",
    "    rating = model2.predict(review_vector)[0]\n",
    "\n",
    "    # Ensure rating is within original bounds\n",
    "    min_rating, max_rating = data['Rating'].min(), data['Rating'].max()\n",
    "    rating = np.clip(rating, min_rating, max_rating)\n",
    "\n",
    "    return f\"Predicted rating: {rating:.2f} (scale: {min_rating}-{max_rating})\"\n",
    "\n",
    "# Test cases\n",
    "test_reviews = [\n",
    "    \"The album was a masterpiece from start to finish\",\n",
    "    \"Some good tracks but overall disappointing\",\n",
    "    \"The vocals were amazing, though the production quality ruined it\",\n",
    "    \"Mediocre at best - nothing special\",\n",
    "    \"This album changed my life! Perfect in every way\",\n",
    "    \"This album was the worst thing I heard in my life, Death to the artist and the producer, disgusting, awful, bad , waste of time\",\n",
    "    \"A genre-defying record that blends jazz, electronica, and rock seamlessly, though some tracks feel unnecessarily long and meandering.\",\n",
    "    \"Despite the hype, the album lacks originality and feels like a rehash of the band's previous work, with only a few standout moments.\",\n",
    "    \"The production is lush and detailed, but the lyrics are pretentious and the melodies forgettable, making for a frustrating listen.\"\n",
    "]\n",
    "# Additional test cases expected to be below 1 rating\n",
    "test_reviews += [\n",
    "    \"Absolutely terrible album, not a single redeeming quality. I regret listening to it.\",\n",
    "    \"Horrible in every way, the worst music I've ever heard.\",\n",
    "    \"Unbearable noise, couldn't finish a single track.\",\n",
    "    \"A complete disaster, avoid at all costs.\",\n",
    "    \"Painful to listen to, a total waste of time.\",\n",
    "    \"Zero talent, zero effort, zero enjoyment.\",\n",
    "    \"This album is an insult to music.\",\n",
    "    \"If I could give it a zero, I would.\",\n",
    "    \"The most disappointing and awful release of the year.\",\n",
    "    \"Disgusting, offensive, and unlistenable.\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(predict_rating(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "54e8e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,3),\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    sublinear_tf=True \n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Review'])\n",
    "vocab = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38f7e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaahs', 'aade', ..., 'zyskuje', 'zz', 'zz top'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "64d9fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "Rating\n",
      "positive    61276\n",
      "neutral     13628\n",
      "negative     2937\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create bins that make sense for your distribution\n",
    "rating_bins = pd.cut(data['Rating'],\n",
    "                    bins=[0, 2.0, 3.5, 5.0],\n",
    "                    labels=['negative', 'neutral', 'positive'])\n",
    "\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(rating_bins.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a892bc3",
   "metadata": {},
   "source": [
    "## word 2 vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51948a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Cleaned_Review' is the column with tokenized text (as lists of words)\n",
    "# If not tokenized, tokenize first:\n",
    "data['tokens'] = data['Cleaned_Review'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model (or load a pre-trained one)\n",
    "w2v_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "def document_vector(word_list):\n",
    "    # Remove out-of-vocabulary words\n",
    "    word_list = [word for word in word_list if word in w2v_model.wv.index_to_key]\n",
    "    if len(word_list) == 0:\n",
    "        return np.zeros(100)\n",
    "    return np.mean(w2v_model.wv[word_list], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9fcdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album',\n",
       " 'song',\n",
       " 'one',\n",
       " 'like',\n",
       " 'de',\n",
       " 'track',\n",
       " 'time',\n",
       " 'music',\n",
       " 'sound',\n",
       " 'really',\n",
       " 'best',\n",
       " 'would',\n",
       " 'la',\n",
       " '!',\n",
       " 'great',\n",
       " 'good',\n",
       " 'que',\n",
       " '?',\n",
       " 'band',\n",
       " 'rock',\n",
       " 'even',\n",
       " 'first',\n",
       " 'much',\n",
       " 'get',\n",
       " 'record',\n",
       " 'still',\n",
       " 'make',\n",
       " 'love',\n",
       " 'guitar',\n",
       " 'way',\n",
       " 'ever',\n",
       " 'e',\n",
       " 'feel',\n",
       " 'well',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'also',\n",
       " 'listen',\n",
       " 'come',\n",
       " 'en',\n",
       " 'could',\n",
       " 'know',\n",
       " 'lyric',\n",
       " 'un',\n",
       " 'vocal',\n",
       " 'say',\n",
       " 'never',\n",
       " 'something',\n",
       " 'year',\n",
       " 'work',\n",
       " 'every',\n",
       " 'el',\n",
       " 'many',\n",
       " 'two',\n",
       " 'though',\n",
       " 'go',\n",
       " 'favorite',\n",
       " 'better',\n",
       " 'metal',\n",
       " 'life',\n",
       " 'people',\n",
       " 'back',\n",
       " 'heard',\n",
       " 'lot',\n",
       " 'end',\n",
       " 'part',\n",
       " 'classic',\n",
       " 'pretty',\n",
       " 'little',\n",
       " 'le',\n",
       " 'take',\n",
       " 'going',\n",
       " 'bit',\n",
       " 'side',\n",
       " 'another',\n",
       " 'new',\n",
       " 'long',\n",
       " 'made',\n",
       " 'day',\n",
       " 'minute',\n",
       " 'probably',\n",
       " 'man',\n",
       " 'got',\n",
       " 'kind',\n",
       " 'perfect',\n",
       " 'quite',\n",
       " 'solo',\n",
       " 'always',\n",
       " 'pop',\n",
       " 'give',\n",
       " 'point',\n",
       " 'want',\n",
       " 'blue',\n",
       " 'see',\n",
       " 'whole',\n",
       " 'hard',\n",
       " 'listening',\n",
       " 'world',\n",
       " 'almost',\n",
       " 'moment',\n",
       " 'start',\n",
       " 'second',\n",
       " 'yet',\n",
       " 'jazz',\n",
       " 'right',\n",
       " 'fan',\n",
       " 'una',\n",
       " 'se',\n",
       " 'production',\n",
       " 'find',\n",
       " 'amazing',\n",
       " 'con',\n",
       " 'release',\n",
       " 'last',\n",
       " 'u',\n",
       " 'riff',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'death',\n",
       " 'everything',\n",
       " 'nothing',\n",
       " 'different',\n",
       " 'greatest',\n",
       " 'far',\n",
       " 'black',\n",
       " 'dark',\n",
       " 'drum',\n",
       " 'actually',\n",
       " 'beatles',\n",
       " 'disco',\n",
       " 'los',\n",
       " 'hear',\n",
       " 'let',\n",
       " 'del',\n",
       " 'without',\n",
       " 'said',\n",
       " 'around',\n",
       " 'anything',\n",
       " 'single',\n",
       " 'voice',\n",
       " 'put',\n",
       " 'title',\n",
       " 'least',\n",
       " 'maybe',\n",
       " 'bad',\n",
       " 'masterpiece',\n",
       " 'enough',\n",
       " 'melody',\n",
       " 'bass',\n",
       " 'musical',\n",
       " 'mind',\n",
       " 'star',\n",
       " 'dylan',\n",
       " 'sure',\n",
       " 'however',\n",
       " 'et',\n",
       " 'piece',\n",
       " 'top',\n",
       " 'line',\n",
       " 'rest',\n",
       " 'style',\n",
       " 'genre',\n",
       " 'play',\n",
       " 'heavy',\n",
       " 'fact',\n",
       " 'may',\n",
       " 'since',\n",
       " 'half',\n",
       " 'word',\n",
       " 'place',\n",
       " 'big',\n",
       " 'feeling',\n",
       " 'away',\n",
       " 'might',\n",
       " 'together',\n",
       " 'si',\n",
       " 'di',\n",
       " 'show',\n",
       " 'seems',\n",
       " 'mean',\n",
       " 'por',\n",
       " 'interesting',\n",
       " 'playing',\n",
       " 'pink',\n",
       " 'como',\n",
       " 'hit',\n",
       " 'three',\n",
       " 'thought',\n",
       " 'next',\n",
       " 'da',\n",
       " 'especially',\n",
       " 'need',\n",
       " 'soul',\n",
       " 'review',\n",
       " 'lo',\n",
       " 'favourite',\n",
       " 'high',\n",
       " 'less',\n",
       " 'course',\n",
       " 'listened',\n",
       " 'reason',\n",
       " 'real',\n",
       " 'idea',\n",
       " 'full',\n",
       " 'definitely',\n",
       " 'else',\n",
       " 'change',\n",
       " 'su',\n",
       " 'overall',\n",
       " 'later',\n",
       " 'zeppelin',\n",
       " 'yes',\n",
       " 'although',\n",
       " 'nice',\n",
       " 'truly',\n",
       " 'na',\n",
       " 'bowie',\n",
       " 'old',\n",
       " 'stuff',\n",
       " 'experience',\n",
       " 'sense',\n",
       " 'artist',\n",
       " 'simply',\n",
       " 'para',\n",
       " 'cover',\n",
       " 'rather',\n",
       " 'came',\n",
       " 'often',\n",
       " 'floyd',\n",
       " 'instrumental',\n",
       " 'close',\n",
       " 'hop',\n",
       " 'verse',\n",
       " 'released',\n",
       " 'm',\n",
       " 'absolutely',\n",
       " 'live',\n",
       " 'already',\n",
       " 'highlight',\n",
       " 'version',\n",
       " 'led',\n",
       " 'theme',\n",
       " 'brilliant',\n",
       " 'along',\n",
       " 'head',\n",
       " 'set',\n",
       " 'fantastic',\n",
       " 'quality',\n",
       " 'stone',\n",
       " 'must',\n",
       " 'il',\n",
       " 'al',\n",
       " 'perhaps',\n",
       " 'piano',\n",
       " 'tune',\n",
       " 'punk',\n",
       " 'throughout',\n",
       " 'cd',\n",
       " 'sort',\n",
       " 'tell',\n",
       " 'note',\n",
       " 'hip',\n",
       " 'keep',\n",
       " 'debut',\n",
       " 'stand',\n",
       " 'kanye',\n",
       " 'art',\n",
       " 'king',\n",
       " 'opinion',\n",
       " 'listener',\n",
       " 'making',\n",
       " 'found',\n",
       " 'completely',\n",
       " 'fun',\n",
       " 'group',\n",
       " 'excellent',\n",
       " 'john',\n",
       " 'unique',\n",
       " 'rap',\n",
       " 'used',\n",
       " 'cool',\n",
       " 'short',\n",
       " 'young',\n",
       " 'atmosphere',\n",
       " 'guy',\n",
       " 'story',\n",
       " 'final',\n",
       " 'w',\n",
       " 'wall',\n",
       " 'catchy',\n",
       " 'heart',\n",
       " 'epic',\n",
       " 'early',\n",
       " 'true',\n",
       " 'certainly',\n",
       " 'everyone',\n",
       " 'entire',\n",
       " 'original',\n",
       " 'simple',\n",
       " 'personal',\n",
       " 'done',\n",
       " 'hell',\n",
       " 'despite',\n",
       " 'progressive',\n",
       " 'four',\n",
       " 'influence',\n",
       " 'chorus',\n",
       " 'acoustic',\n",
       " 'feature',\n",
       " 'sometimes',\n",
       " 'shit',\n",
       " 'concept',\n",
       " 'look',\n",
       " 'opening',\n",
       " 'incredible',\n",
       " 'seem',\n",
       " 'dream',\n",
       " 'enjoy',\n",
       " 'run',\n",
       " 'perfectly',\n",
       " 'section',\n",
       " 'rating',\n",
       " 'number',\n",
       " 'instrument',\n",
       " 'example',\n",
       " 'son',\n",
       " 'friend',\n",
       " 'either',\n",
       " 'flow',\n",
       " 'played',\n",
       " 'singing',\n",
       " 'oh',\n",
       " 'est',\n",
       " 'fucking',\n",
       " 'previous',\n",
       " 'name',\n",
       " 'strong',\n",
       " 'ok',\n",
       " 'mood',\n",
       " 'plus',\n",
       " 'awesome',\n",
       " 'understand',\n",
       " 'turn',\n",
       " 'someone',\n",
       " 'god',\n",
       " 'career',\n",
       " 'performance',\n",
       " 'power',\n",
       " 'anyone',\n",
       " 'believe',\n",
       " 'night',\n",
       " 'getting',\n",
       " 'light',\n",
       " 'matter',\n",
       " 'che',\n",
       " 'este',\n",
       " 'hiphop',\n",
       " 'history',\n",
       " 'prog',\n",
       " 'wish',\n",
       " 'left',\n",
       " 'others',\n",
       " 'hand',\n",
       " 'boy',\n",
       " 'use',\n",
       " 'folk',\n",
       " 'finally',\n",
       " 'call',\n",
       " 'pero',\n",
       " 'try',\n",
       " 'songwriting',\n",
       " 'era',\n",
       " 'kid',\n",
       " 'trying',\n",
       " 'die',\n",
       " 'easily',\n",
       " 'lead',\n",
       " 'today',\n",
       " 'help',\n",
       " 'become',\n",
       " 'emotion',\n",
       " 'worth',\n",
       " 'noise',\n",
       " 'recorded',\n",
       " 'recording',\n",
       " 'mais',\n",
       " 'level',\n",
       " 'deep',\n",
       " 'guess',\n",
       " 'musician',\n",
       " 'important',\n",
       " 'bob',\n",
       " 'break',\n",
       " 'remember',\n",
       " 'instead',\n",
       " 'add',\n",
       " 'took',\n",
       " 'written',\n",
       " 'sample',\n",
       " 'rhythm',\n",
       " 'beginning',\n",
       " 'closer',\n",
       " 'five',\n",
       " 'girl',\n",
       " 'tone',\n",
       " 'mile',\n",
       " 'water',\n",
       " 'ballad',\n",
       " 'coming',\n",
       " 'radiohead',\n",
       " 'lost',\n",
       " 'studio',\n",
       " 'boring',\n",
       " 'effect',\n",
       " 'qui',\n",
       " 'moon',\n",
       " 'crimson',\n",
       " 'material',\n",
       " 'weird',\n",
       " 'emotional',\n",
       " 'cut',\n",
       " 'solid',\n",
       " 'talk',\n",
       " 'felt',\n",
       " 'form',\n",
       " 'fall',\n",
       " 'started',\n",
       " 'experimental',\n",
       " 'past',\n",
       " 'behind',\n",
       " 'couple',\n",
       " 'element',\n",
       " 'sabbath',\n",
       " 'sounding',\n",
       " 'z',\n",
       " 'mix',\n",
       " 'open',\n",
       " 'powerful',\n",
       " 'um',\n",
       " 'easy',\n",
       " 'lbum',\n",
       " 'genius',\n",
       " 'problem',\n",
       " 'talking',\n",
       " 'decade',\n",
       " 'paul',\n",
       " 'money',\n",
       " 'wrong',\n",
       " 'incredibly',\n",
       " 'similar',\n",
       " 'home',\n",
       " 'able',\n",
       " 'fit',\n",
       " 'damn',\n",
       " 'roll',\n",
       " 'hook',\n",
       " 'crazy',\n",
       " 'alone',\n",
       " 'hate',\n",
       " 'due',\n",
       " 'groove',\n",
       " 'mostly',\n",
       " 'begin',\n",
       " 'collection',\n",
       " 'funk',\n",
       " 'face',\n",
       " 'psychedelic',\n",
       " 'du',\n",
       " 'machine',\n",
       " 'slow',\n",
       " 'pure',\n",
       " 'given',\n",
       " 'road',\n",
       " 'electric',\n",
       " 'eye',\n",
       " 'late',\n",
       " 'main',\n",
       " 'lp',\n",
       " 'case',\n",
       " 'huge',\n",
       " 'hold',\n",
       " 'fine',\n",
       " 'create',\n",
       " 'went',\n",
       " 'wonder',\n",
       " 'yeah',\n",
       " 'ce',\n",
       " 'intro',\n",
       " 'human',\n",
       " 'anyway',\n",
       " 'wait',\n",
       " 'pa',\n",
       " 'low',\n",
       " 'saying',\n",
       " 'looking',\n",
       " 'particularly',\n",
       " 'maiden',\n",
       " 'house',\n",
       " 'writing',\n",
       " 'special',\n",
       " 'computer',\n",
       " 'tyler',\n",
       " 'wonderful',\n",
       " 'term',\n",
       " 'extremely',\n",
       " 'doubt',\n",
       " 'ear',\n",
       " 'fuck',\n",
       " 'une',\n",
       " 'nirvana',\n",
       " 'radio',\n",
       " 'strange',\n",
       " 'within',\n",
       " 'popular',\n",
       " 'th',\n",
       " 'exactly',\n",
       " 'arrangement',\n",
       " 'child',\n",
       " 'middle',\n",
       " 'melodic',\n",
       " 'care',\n",
       " 'future',\n",
       " 'white',\n",
       " 'composition',\n",
       " 'lack',\n",
       " 'david',\n",
       " 'general',\n",
       " 'chord',\n",
       " 'kendrick',\n",
       " 'called',\n",
       " 'slightly',\n",
       " 'seen',\n",
       " 'gone',\n",
       " 'stop',\n",
       " 'heaven',\n",
       " 'project',\n",
       " 'drumming',\n",
       " 'among',\n",
       " 'musically',\n",
       " 'clear',\n",
       " 'opener',\n",
       " 'absolute',\n",
       " 'possibly',\n",
       " 'member',\n",
       " 'energy',\n",
       " 'pick',\n",
       " 'filler',\n",
       " 'nearly',\n",
       " 'somewhat',\n",
       " 'instrumentation',\n",
       " 'todo',\n",
       " 'structure',\n",
       " 'hearing',\n",
       " 'woman',\n",
       " 'mi',\n",
       " 'string',\n",
       " 'effort',\n",
       " 'city',\n",
       " 'scene',\n",
       " 'attention',\n",
       " 'bring',\n",
       " 'step',\n",
       " 'enjoyable',\n",
       " 'sad',\n",
       " 'memorable',\n",
       " 'lyrical',\n",
       " 'b',\n",
       " 'write',\n",
       " 'impressive',\n",
       " 'fire',\n",
       " 'wanted',\n",
       " 'appreciate',\n",
       " 'red',\n",
       " 'robert',\n",
       " 'complete',\n",
       " 'sun',\n",
       " 'highly',\n",
       " 'forever',\n",
       " 'dog',\n",
       " 'period',\n",
       " 'essential',\n",
       " 'shine',\n",
       " 'key',\n",
       " 'upon',\n",
       " 'disc',\n",
       " 'dans',\n",
       " 'modern',\n",
       " 'across',\n",
       " 'towards',\n",
       " 'listens',\n",
       " 'nie',\n",
       " 'background',\n",
       " 'overrated',\n",
       " 'obviously',\n",
       " 'hour',\n",
       " 'complex',\n",
       " 'result',\n",
       " 'particular',\n",
       " 'keyboard',\n",
       " 'act',\n",
       " 'third',\n",
       " 'mark',\n",
       " 'sky',\n",
       " 'move',\n",
       " 'person',\n",
       " 'free',\n",
       " 'msica',\n",
       " 'honestly',\n",
       " 'near',\n",
       " 'car',\n",
       " 'raw',\n",
       " 'creative',\n",
       " 'double',\n",
       " 'beauty',\n",
       " 'basically',\n",
       " 'known',\n",
       " 'earlier',\n",
       " 'west',\n",
       " 'knew',\n",
       " 'jam',\n",
       " 'ya',\n",
       " 'country',\n",
       " 'whatever',\n",
       " 'finest',\n",
       " 'none',\n",
       " 'wind',\n",
       " 'beyond',\n",
       " 'build',\n",
       " 'somehow',\n",
       " 'edge',\n",
       " 'considered',\n",
       " 'drug',\n",
       " 'smith',\n",
       " 'standard',\n",
       " 'neil',\n",
       " 'giving',\n",
       " 'uma',\n",
       " 'soft',\n",
       " 'peak',\n",
       " 'state',\n",
       " 'dead',\n",
       " 'sing',\n",
       " 'joy',\n",
       " 'usually',\n",
       " 'leave',\n",
       " 'vibe',\n",
       " 'singer',\n",
       " 'blood',\n",
       " 'liked',\n",
       " 'loved',\n",
       " 'sus',\n",
       " 'became',\n",
       " 'ten',\n",
       " 'changed',\n",
       " 'ending',\n",
       " 'list',\n",
       " 'taste',\n",
       " 'bien',\n",
       " 'je',\n",
       " 'certain',\n",
       " 'kick',\n",
       " 'produced',\n",
       " 'space',\n",
       " 'mr',\n",
       " 'age',\n",
       " 'soundtrack',\n",
       " 'nature',\n",
       " 'taking',\n",
       " 'length',\n",
       " 'non',\n",
       " 'war',\n",
       " 'der',\n",
       " 'sin',\n",
       " 'worst',\n",
       " 'und',\n",
       " 'dance',\n",
       " 'rain',\n",
       " 'whether',\n",
       " 'possible',\n",
       " 'ride',\n",
       " 'hope',\n",
       " 'school',\n",
       " 'per',\n",
       " 'following',\n",
       " 'ambient',\n",
       " 'pour',\n",
       " 'ago',\n",
       " 'present',\n",
       " 'electronic',\n",
       " 'longer',\n",
       " 'type',\n",
       " 'par',\n",
       " 'totally',\n",
       " 'consider',\n",
       " 'clearly',\n",
       " 'compared',\n",
       " 'ser',\n",
       " 'rolling',\n",
       " 'talent',\n",
       " 'fully',\n",
       " 'touch',\n",
       " 'mention',\n",
       " 'street',\n",
       " 'soon',\n",
       " 'obvious',\n",
       " 'prefer',\n",
       " 'finish',\n",
       " 'gave',\n",
       " 'uno',\n",
       " 'frank',\n",
       " 'except',\n",
       " 'george',\n",
       " 'created',\n",
       " 'page',\n",
       " 'read',\n",
       " 'several',\n",
       " 'approach',\n",
       " 'n',\n",
       " 'lyrically',\n",
       " 'direction',\n",
       " 'weak',\n",
       " 'imagine',\n",
       " 'nevermind',\n",
       " 'fast',\n",
       " 'etc',\n",
       " 'funky',\n",
       " 'intense',\n",
       " 'wave',\n",
       " 'movie',\n",
       " 'contains',\n",
       " 'film',\n",
       " 'hendrix',\n",
       " 'american',\n",
       " 'sweet',\n",
       " 'brings',\n",
       " 'return',\n",
       " 'describe',\n",
       " 'amount',\n",
       " 'happy',\n",
       " 'follow',\n",
       " 'hey',\n",
       " 'rapper',\n",
       " 'banda',\n",
       " 'apart',\n",
       " 'taken',\n",
       " 'seriously',\n",
       " 'davis',\n",
       " 'straight',\n",
       " 'thinking',\n",
       " 'remains',\n",
       " 'unlike',\n",
       " 'synth',\n",
       " 'inspired',\n",
       " 'com',\n",
       " 'famous',\n",
       " 'lennon',\n",
       " 'baby',\n",
       " 'ne',\n",
       " 'game',\n",
       " 'living',\n",
       " 'master',\n",
       " 'buy',\n",
       " 'bitch',\n",
       " 'sonic',\n",
       " 'decent',\n",
       " 'tom',\n",
       " 'journey',\n",
       " 'consistent',\n",
       " 'bought',\n",
       " 'cry',\n",
       " 'picture',\n",
       " 'major',\n",
       " 'revolver',\n",
       " 'memory',\n",
       " 'canciones',\n",
       " 'loud',\n",
       " 'gorgeous',\n",
       " 'tempo',\n",
       " 'discography',\n",
       " 'question',\n",
       " 'character',\n",
       " 'job',\n",
       " 'aspect',\n",
       " 'ability',\n",
       " 'station',\n",
       " 'te',\n",
       " 'wild',\n",
       " 'personally',\n",
       " 'aside',\n",
       " 'cold',\n",
       " 'sur',\n",
       " 'surprise',\n",
       " 'swan',\n",
       " 'iron',\n",
       " 'biggest',\n",
       " 'fresh',\n",
       " 'room',\n",
       " 'issue',\n",
       " 'message',\n",
       " 'reach',\n",
       " 'difficult',\n",
       " 'grunge',\n",
       " 'starting',\n",
       " 'offer',\n",
       " 'thrash',\n",
       " 'honest',\n",
       " 'vision',\n",
       " 'blonde',\n",
       " 'success',\n",
       " 'instrumentals',\n",
       " 'harmony',\n",
       " 'alternative',\n",
       " 'cest',\n",
       " 'meaning',\n",
       " 'relationship',\n",
       " 'avec',\n",
       " 'pi',\n",
       " 'spirit',\n",
       " 'deserves',\n",
       " 'annoying',\n",
       " 'check',\n",
       " 'mother',\n",
       " 'decided',\n",
       " 'month',\n",
       " 'average',\n",
       " 'jest',\n",
       " 'deal',\n",
       " 'genesis',\n",
       " 'funny',\n",
       " 'accessible',\n",
       " 'including',\n",
       " 'coltrane',\n",
       " 'ma',\n",
       " 'context',\n",
       " 'immediately',\n",
       " 'player',\n",
       " 'holy',\n",
       " 'entirely',\n",
       " 'indie',\n",
       " 'haunting',\n",
       " 'esta',\n",
       " 'focus',\n",
       " 'unfortunately',\n",
       " 'followed',\n",
       " 'curtis',\n",
       " 'magic',\n",
       " 'sounded',\n",
       " 'becomes',\n",
       " 'animal',\n",
       " 'expect',\n",
       " 'warm',\n",
       " 'wrote',\n",
       " 'odd',\n",
       " 'pepper',\n",
       " 'individual',\n",
       " 'statement',\n",
       " 'based',\n",
       " 'au',\n",
       " 'massive',\n",
       " 'fade',\n",
       " 'hill',\n",
       " 'turned',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'indeed',\n",
       " 'sings',\n",
       " 'stay',\n",
       " 'river',\n",
       " 'inside',\n",
       " 'diamond',\n",
       " 'manages',\n",
       " 'no',\n",
       " 'serious',\n",
       " 'rapping',\n",
       " 'mccartney',\n",
       " 'fantasy',\n",
       " 'percussion',\n",
       " 'nowhere',\n",
       " 'tour',\n",
       " 'seemed',\n",
       " 'repetitive',\n",
       " 'earth',\n",
       " 'killer',\n",
       " 'influential',\n",
       " 'forget',\n",
       " 'plant',\n",
       " 'drive',\n",
       " 'kill',\n",
       " 'latter',\n",
       " 'mainstream',\n",
       " 'book',\n",
       " 'outside',\n",
       " 'small',\n",
       " 'tout',\n",
       " 'variety',\n",
       " 'bruce',\n",
       " 'praise',\n",
       " 'sex',\n",
       " 'technical',\n",
       " 'synths',\n",
       " 'l',\n",
       " 'carry',\n",
       " 'ha',\n",
       " 'chance',\n",
       " 'perfection',\n",
       " 'delivery',\n",
       " 'stick',\n",
       " 'mentioned',\n",
       " 'somewhere',\n",
       " 'actual',\n",
       " 'guitarist',\n",
       " 'saw',\n",
       " 'running',\n",
       " 'recommend',\n",
       " 'producer',\n",
       " 'eventually',\n",
       " 'order',\n",
       " 'ocean',\n",
       " 'self',\n",
       " 'vinyl',\n",
       " 'organ',\n",
       " 'attempt',\n",
       " 'doom',\n",
       " 'muy',\n",
       " 'slowly',\n",
       " 'tried',\n",
       " 'loveless',\n",
       " 'sea',\n",
       " 'brain',\n",
       " 'born',\n",
       " 'evil',\n",
       " 'trip',\n",
       " 'lady',\n",
       " 'do',\n",
       " 'session',\n",
       " 'okay',\n",
       " 'front',\n",
       " 'pleasure',\n",
       " 'closing',\n",
       " 'echo',\n",
       " 'co',\n",
       " 'hype',\n",
       " 'st',\n",
       " 'admit',\n",
       " 'interlude',\n",
       " 'atmospheric',\n",
       " 'pixy',\n",
       " 'dynamic',\n",
       " 'content',\n",
       " 'century',\n",
       " 'eno',\n",
       " 'rate',\n",
       " 'cancin',\n",
       " 'detail',\n",
       " 'drummer',\n",
       " 'pain',\n",
       " 'grand',\n",
       " 'lie',\n",
       " 'higher',\n",
       " 'realize',\n",
       " 'mingus',\n",
       " 'considering',\n",
       " 'influenced',\n",
       " 'abbey',\n",
       " 'michael',\n",
       " 'transition',\n",
       " 'filled',\n",
       " 'van',\n",
       " 'green',\n",
       " 'mejor',\n",
       " 'comparison',\n",
       " 'artistic',\n",
       " 'needed',\n",
       " 'exception',\n",
       " 'ian',\n",
       " 'subject',\n",
       " 'appeal',\n",
       " 'bar',\n",
       " 'force',\n",
       " 'fusion',\n",
       " 'impossible',\n",
       " 'rocker',\n",
       " 'mine',\n",
       " 'angel',\n",
       " 'steve',\n",
       " 'brother',\n",
       " 'smooth',\n",
       " 'pull',\n",
       " 'ahead',\n",
       " 'rubber',\n",
       " 'backing',\n",
       " 'leaf',\n",
       " 'creating',\n",
       " 'generation',\n",
       " 'otherwise',\n",
       " 'super',\n",
       " 'kanyes',\n",
       " 'reminds',\n",
       " 'algo',\n",
       " 'as',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w2v = data['Cleaned_Review'].apply(lambda x: document_vector(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w2v\n",
    "# #save in a csv\n",
    "# # Convert the Series of numpy arrays to a DataFrame\n",
    "# X_w2v_df = X_w2v.apply(pd.Series)\n",
    "# # Optionally, add the index or an identifier if needed\n",
    "# X_w2v_df.to_csv('./dataset/X_w2v_vectors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d3b79",
   "metadata": {},
   "source": [
    "## splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99568a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f062",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68306cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.16347329822553325\n",
      "R2: 0.7817825154835283\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Higher weights for rare ratings\n",
    "\n",
    "weights = compute_sample_weight(\n",
    "    class_weight={\n",
    "        'negative': 10.0,\n",
    "        'neutral': 3.0,\n",
    "        'positive': 1.0\n",
    "    },\n",
    "    y=rating_bins\n",
    ")\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X,y,sample_weight=weights)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849c4ed7",
   "metadata": {},
   "source": [
    "## hide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "# from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "# from sklearn.svm import SVR\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from xgboost import XGBRegressor\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(alpha=1.0,solver='lsqr')\n",
    "    # 'RandomForestRegressor':RandomForestRegressor(),\n",
    "    # 'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    # 'SVR':SVR(),\n",
    "    # 'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    # 'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    # 'XGBRegressor':XGBRegressor(),\n",
    "    # 'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "695a124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "metrics_list = []\n",
    "\n",
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7625567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.817187</td>\n",
       "      <td>0.903984</td>\n",
       "      <td>-0.090847</td>\n",
       "      <td>0.690256</td>\n",
       "      <td>0.216402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.476026</td>\n",
       "      <td>0.689946</td>\n",
       "      <td>0.364562</td>\n",
       "      <td>0.510050</td>\n",
       "      <td>0.177092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0  LinearRegression  0.817187  0.903984 -0.090847  0.690256  0.216402\n",
       "1             Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2             Ridge  0.476026  0.689946  0.364562  0.510050  0.177092"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef68ff7",
   "metadata": {},
   "source": [
    "## testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a9a2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating for the review 'mid' is: 3.15\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "text = input(\"Enter review: \")\n",
    "\n",
    "# Clean the review text\n",
    "clean_data = preprocess_text(text)  # This should return a cleaned string\n",
    "\n",
    "# Vectorize using the already trained vectorizer (do NOT use fit_transform)\n",
    "X = tfidf_vectorizer.transform([clean_data])  # Wrap in a list to avoid error\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_rating = model.predict(X)\n",
    "\n",
    "# Output the result\n",
    "print(f\"The predicted rating for the review '{text}' is: {predicted_rating[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "091b0cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: The album was a masterpiece from start to finish\n",
      "Predicted rating: 4.98 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Some good tracks but overall disappointing\n",
      "Predicted rating: 3.13 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The vocals were amazing, though the production quality ruined it\n",
      "Predicted rating: 3.16 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Mediocre at best - nothing special\n",
      "Predicted rating: 2.73 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album changed my life! Perfect in every way\n",
      "Predicted rating: 5.00 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album was the worst thing I heard in my life, Death to the artist and the producer, disgusting, awful, bad , waste of time\n",
      "Predicted rating: 1.05 (scale: 0.5-5.0)\n",
      "\n",
      "Review: A genre-defying record that blends jazz, electronica, and rock seamlessly, though some tracks feel unnecessarily long and meandering.\n",
      "Predicted rating: 3.20 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Despite the hype, the album lacks originality and feels like a rehash of the band's previous work, with only a few standout moments.\n",
      "Predicted rating: 2.09 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The production is lush and detailed, but the lyrics are pretentious and the melodies forgettable, making for a frustrating listen.\n",
      "Predicted rating: 2.43 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Absolutely terrible album, not a single redeeming quality. I regret listening to it.\n",
      "Predicted rating: 2.06 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Horrible in every way, the worst music I've ever heard.\n",
      "Predicted rating: 2.92 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Unbearable noise, couldn't finish a single track.\n",
      "Predicted rating: 3.69 (scale: 0.5-5.0)\n",
      "\n",
      "Review: A complete disaster, avoid at all costs.\n",
      "Predicted rating: 1.88 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Painful to listen to, a total waste of time.\n",
      "Predicted rating: 2.92 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Zero talent, zero effort, zero enjoyment.\n",
      "Predicted rating: 2.62 (scale: 0.5-5.0)\n",
      "\n",
      "Review: This album is an insult to music.\n",
      "Predicted rating: 3.96 (scale: 0.5-5.0)\n",
      "\n",
      "Review: If I could give it a zero, I would.\n",
      "Predicted rating: 3.37 (scale: 0.5-5.0)\n",
      "\n",
      "Review: The most disappointing and awful release of the year.\n",
      "Predicted rating: 1.23 (scale: 0.5-5.0)\n",
      "\n",
      "Review: Disgusting, offensive, and unlistenable.\n",
      "Predicted rating: 1.99 (scale: 0.5-5.0)\n"
     ]
    }
   ],
   "source": [
    "def predict_rating(review):\n",
    "    # Preprocess\n",
    "    processed_review = preprocess_text(review)\n",
    "\n",
    "    # Transform\n",
    "    review_vector = tfidf_vectorizer.transform([processed_review])\n",
    "\n",
    "    # Predict\n",
    "    rating = model.predict(review_vector)[0]\n",
    "\n",
    "    # Ensure rating is within original bounds\n",
    "    min_rating, max_rating = data['Rating'].min(), data['Rating'].max()\n",
    "    rating = np.clip(rating, min_rating, max_rating)\n",
    "\n",
    "    return f\"Predicted rating: {rating:.2f} (scale: {min_rating}-{max_rating})\"\n",
    "\n",
    "# Test cases\n",
    "test_reviews = [\n",
    "    \"The album was a masterpiece from start to finish\",\n",
    "    \"Some good tracks but overall disappointing\",\n",
    "    \"The vocals were amazing, though the production quality ruined it\",\n",
    "    \"Mediocre at best - nothing special\",\n",
    "    \"This album changed my life! Perfect in every way\",\n",
    "    \"This album was the worst thing I heard in my life, Death to the artist and the producer, disgusting, awful, bad , waste of time\",\n",
    "    \"A genre-defying record that blends jazz, electronica, and rock seamlessly, though some tracks feel unnecessarily long and meandering.\",\n",
    "    \"Despite the hype, the album lacks originality and feels like a rehash of the band's previous work, with only a few standout moments.\",\n",
    "    \"The production is lush and detailed, but the lyrics are pretentious and the melodies forgettable, making for a frustrating listen.\"\n",
    "]\n",
    "# Additional test cases expected to be below 1 rating\n",
    "test_reviews += [\n",
    "    \"Absolutely terrible album, not a single redeeming quality. I regret listening to it.\",\n",
    "    \"Horrible in every way, the worst music I've ever heard.\",\n",
    "    \"Unbearable noise, couldn't finish a single track.\",\n",
    "    \"A complete disaster, avoid at all costs.\",\n",
    "    \"Painful to listen to, a total waste of time.\",\n",
    "    \"Zero talent, zero effort, zero enjoyment.\",\n",
    "    \"This album is an insult to music.\",\n",
    "    \"If I could give it a zero, I would.\",\n",
    "    \"The most disappointing and awful release of the year.\",\n",
    "    \"Disgusting, offensive, and unlistenable.\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    print(f\"\\nReview: {review}\")\n",
    "    print(predict_rating(review))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
