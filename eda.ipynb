{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af24d0",
   "metadata": {},
   "source": [
    "## Exploraty Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da38a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  i think i actually under-rate ok computer if a...     5.0\n",
       "1  i get why radiohead rub a lot of people the wr...     5.0\n",
       "2  i would like to think i am good about not lett...     4.5\n",
       "3  there are radiohead devotees like there were o...     4.0\n",
       "4  i wrote a shining excellent review for this al...     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/music_album_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 80271\n",
      "Rating distribution:\n",
      "Rating\n",
      "5.0    29534\n",
      "4.5    17793\n",
      "4.0    14213\n",
      "3.5     7048\n",
      "3.0     4430\n",
      "2.5     2210\n",
      "2.0     1396\n",
      "1.5      640\n",
      "1.0      525\n",
      "0.5      398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(f\"Rating distribution:\\n{df['Rating'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb8eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review      26\n",
       "Rating    2084\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f313865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d4e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tokenizes the text,lowercase the text, remove stopwords, and lemmatize the text \n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)  # Keep !? for sentiment\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>think actually underrate ok computer anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>get radiohead rub lot people wrong way lot peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>would like think good letting wider critical w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>radiohead devotee like bowie devotee find unex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wrote shining excellent review album browser w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  \\\n",
       "0  i think i actually under-rate ok computer if a...     5.0   \n",
       "1  i get why radiohead rub a lot of people the wr...     5.0   \n",
       "2  i would like to think i am good about not lett...     4.5   \n",
       "3  there are radiohead devotees like there were o...     4.0   \n",
       "4  i wrote a shining excellent review for this al...     5.0   \n",
       "\n",
       "                                      Cleaned_Review  \n",
       "0  think actually underrate ok computer anything ...  \n",
       "1  get radiohead rub lot people wrong way lot peo...  \n",
       "2  would like think good letting wider critical w...  \n",
       "3  radiohead devotee like bowie devotee find unex...  \n",
       "4  wrote shining excellent review album browser w...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'] = df['Review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f5a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7734a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb80a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the empty strings in cleaned_review column\n",
    "df = df[df['Cleaned_Review'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0293cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f3af1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_csv \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/cleaned_music_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_csv = df.to_csv('./dataset/cleaned_music_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6dc66420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review            0\n",
       "Rating            0\n",
       "Cleaned_Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/cleaned_music_reviews.csv')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "54e8e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    ngram_range=(1,3),\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    "    sublinear_tf=True \n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Review'])\n",
    "vocab = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "38f7e407",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'aaaahs', 'aade', ..., 'zyskuje', 'zz', 'zz top'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before resampling:\n",
      "Rating\n",
      "positive    61276\n",
      "neutral     13628\n",
      "negative     2937\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create bins that make sense for your distribution\n",
    "rating_bins = pd.cut(data['Rating'], \n",
    "                    bins=[0, 2.0, 3.5, 5.0],\n",
    "                    labels=['negative', 'neutral', 'positive'])\n",
    "\n",
    "print(\"Class distribution before resampling:\")\n",
    "print(rating_bins.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "74ea5af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class counts:\n",
      " Rating\n",
      "positive    61276\n",
      "neutral     13628\n",
      "negative     2937\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Check original counts\n",
    "original_counts = pd.Series(rating_bins).value_counts()\n",
    "print(\"Original class counts:\\n\", original_counts)\n",
    "\n",
    "# Set target sizes HIGHER than original counts\n",
    "target_sizes = {\n",
    "    'negative': original_counts['negative'] * 3,  # 3x oversampling\n",
    "    'neutral': original_counts['neutral'] * 2,    # 2x oversampling\n",
    "    'positive': original_counts['positive']       # Keep original count\n",
    "}\n",
    "\n",
    "smote = SMOTE(sampling_strategy=target_sizes)\n",
    "X_res, y_res = smote.fit_resample(X, rating_bins)  # X_tfidf must be numeric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca231ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get original rating values for each class (using median)\n",
    "rating_map = {\n",
    "    'negative': data[rating_bins == 'negative']['Rating'].median(),\n",
    "    'neutral': data[rating_bins == 'neutral']['Rating'].median(), \n",
    "    'positive': data[rating_bins == 'positive']['Rating'].median()\n",
    "}\n",
    "\n",
    "# Create balanced DataFrame\n",
    "balanced_df = pd.DataFrame({\n",
    "    'Features': [x.toarray().flatten() for x in X_res],  # Convert sparse matrix\n",
    "    'Rating': [rating_map[cls] for cls in y_res]  # Map class to original rating value\n",
    "})\n",
    "\n",
    "print(\"New class distribution:\")\n",
    "print(pd.Series(y_res).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d28c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_res, \n",
    "    y_res.map(rating_map),  # Use mapped rating values\n",
    "    test_size=0.2,\n",
    "    stratify=y_res  # Maintain class balance\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda8fe0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Calculate inverse frequency weights\n",
    "class_weights = {\n",
    "    'negative': 1 / original_counts['negative'],\n",
    "    'neutral': 1 / original_counts['neutral'],\n",
    "    'positive': 1 / original_counts['positive']\n",
    "}\n",
    "\n",
    "sample_weights = y_res.map(class_weights)\n",
    "\n",
    "model = Ridge(alpha=1.0)\n",
    "model.fit(X_train, y_train, sample_weight=sample_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53cffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    print(f\"MSE: {mean_squared_error(y_true, y_pred):.4f}\")\n",
    "    print(f\"RÂ²: {r2_score(y_true, y_pred):.4f}\")\n",
    "    \n",
    "    # Per-class evaluation\n",
    "    for cls in ['negative', 'neutral', 'positive']:\n",
    "        mask = (y_res == cls)\n",
    "        cls_mse = mean_squared_error(y_true[mask], y_pred[mask])\n",
    "        print(f\"{cls} MSE: {cls_mse:.4f}\")\n",
    "\n",
    "print(\"=== Train Evaluation ===\")\n",
    "evaluate(model, X_train, y_train)\n",
    "\n",
    "print(\"\\n=== Test Evaluation ===\") \n",
    "evaluate(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75741241",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(text):\n",
    "    # Preprocess and vectorize\n",
    "    text_vec = tfidf.transform([text])\n",
    "    \n",
    "    # Predict\n",
    "    raw_pred = model.predict(text_vec)[0]\n",
    "    \n",
    "    # Apply class-based constraints\n",
    "    if 'awful' in text or 'terrible' in text:\n",
    "        return min(raw_pred, 1.5)  # Cap negative reviews\n",
    "    elif 'excellent' in text or 'perfect' in text:\n",
    "        return max(raw_pred, 4.0)  # Floor positive reviews\n",
    "    else:\n",
    "        return np.clip(raw_pred, 1.0, 5.0)\n",
    "\n",
    "# Test\n",
    "test_reviews = [\n",
    "    \"This was terrible and awful\",\n",
    "    \"Perfect experience, excellent service\",\n",
    "    \"It was okay, nothing special\"\n",
    "]\n",
    "\n",
    "for review in test_reviews:\n",
    "    print(f\"\\nReview: {review[:50]}...\")\n",
    "    print(f\"Predicted rating: {predict_rating(review):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a892bc3",
   "metadata": {},
   "source": [
    "## word 2 vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51948a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Cleaned_Review' is the column with tokenized text (as lists of words)\n",
    "# If not tokenized, tokenize first:\n",
    "data['tokens'] = data['Cleaned_Review'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model (or load a pre-trained one)\n",
    "w2v_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "def document_vector(word_list):\n",
    "    # Remove out-of-vocabulary words\n",
    "    word_list = [word for word in word_list if word in w2v_model.wv.index_to_key]\n",
    "    if len(word_list) == 0:\n",
    "        return np.zeros(100)\n",
    "    return np.mean(w2v_model.wv[word_list], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9fcdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album',\n",
       " 'song',\n",
       " 'one',\n",
       " 'like',\n",
       " 'de',\n",
       " 'track',\n",
       " 'time',\n",
       " 'music',\n",
       " 'sound',\n",
       " 'really',\n",
       " 'best',\n",
       " 'would',\n",
       " 'la',\n",
       " '!',\n",
       " 'great',\n",
       " 'good',\n",
       " 'que',\n",
       " '?',\n",
       " 'band',\n",
       " 'rock',\n",
       " 'even',\n",
       " 'first',\n",
       " 'much',\n",
       " 'get',\n",
       " 'record',\n",
       " 'still',\n",
       " 'make',\n",
       " 'love',\n",
       " 'guitar',\n",
       " 'way',\n",
       " 'ever',\n",
       " 'e',\n",
       " 'feel',\n",
       " 'well',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'also',\n",
       " 'listen',\n",
       " 'come',\n",
       " 'en',\n",
       " 'could',\n",
       " 'know',\n",
       " 'lyric',\n",
       " 'un',\n",
       " 'vocal',\n",
       " 'say',\n",
       " 'never',\n",
       " 'something',\n",
       " 'year',\n",
       " 'work',\n",
       " 'every',\n",
       " 'el',\n",
       " 'many',\n",
       " 'two',\n",
       " 'though',\n",
       " 'go',\n",
       " 'favorite',\n",
       " 'better',\n",
       " 'metal',\n",
       " 'life',\n",
       " 'people',\n",
       " 'back',\n",
       " 'heard',\n",
       " 'lot',\n",
       " 'end',\n",
       " 'part',\n",
       " 'classic',\n",
       " 'pretty',\n",
       " 'little',\n",
       " 'le',\n",
       " 'take',\n",
       " 'going',\n",
       " 'bit',\n",
       " 'side',\n",
       " 'another',\n",
       " 'new',\n",
       " 'long',\n",
       " 'made',\n",
       " 'day',\n",
       " 'minute',\n",
       " 'probably',\n",
       " 'man',\n",
       " 'got',\n",
       " 'kind',\n",
       " 'perfect',\n",
       " 'quite',\n",
       " 'solo',\n",
       " 'always',\n",
       " 'pop',\n",
       " 'give',\n",
       " 'point',\n",
       " 'want',\n",
       " 'blue',\n",
       " 'see',\n",
       " 'whole',\n",
       " 'hard',\n",
       " 'listening',\n",
       " 'world',\n",
       " 'almost',\n",
       " 'moment',\n",
       " 'start',\n",
       " 'second',\n",
       " 'yet',\n",
       " 'jazz',\n",
       " 'right',\n",
       " 'fan',\n",
       " 'una',\n",
       " 'se',\n",
       " 'production',\n",
       " 'find',\n",
       " 'amazing',\n",
       " 'con',\n",
       " 'release',\n",
       " 'last',\n",
       " 'u',\n",
       " 'riff',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'death',\n",
       " 'everything',\n",
       " 'nothing',\n",
       " 'different',\n",
       " 'greatest',\n",
       " 'far',\n",
       " 'black',\n",
       " 'dark',\n",
       " 'drum',\n",
       " 'actually',\n",
       " 'beatles',\n",
       " 'disco',\n",
       " 'los',\n",
       " 'hear',\n",
       " 'let',\n",
       " 'del',\n",
       " 'without',\n",
       " 'said',\n",
       " 'around',\n",
       " 'anything',\n",
       " 'single',\n",
       " 'voice',\n",
       " 'put',\n",
       " 'title',\n",
       " 'least',\n",
       " 'maybe',\n",
       " 'bad',\n",
       " 'masterpiece',\n",
       " 'enough',\n",
       " 'melody',\n",
       " 'bass',\n",
       " 'musical',\n",
       " 'mind',\n",
       " 'star',\n",
       " 'dylan',\n",
       " 'sure',\n",
       " 'however',\n",
       " 'et',\n",
       " 'piece',\n",
       " 'top',\n",
       " 'line',\n",
       " 'rest',\n",
       " 'style',\n",
       " 'genre',\n",
       " 'play',\n",
       " 'heavy',\n",
       " 'fact',\n",
       " 'may',\n",
       " 'since',\n",
       " 'half',\n",
       " 'word',\n",
       " 'place',\n",
       " 'big',\n",
       " 'feeling',\n",
       " 'away',\n",
       " 'might',\n",
       " 'together',\n",
       " 'si',\n",
       " 'di',\n",
       " 'show',\n",
       " 'seems',\n",
       " 'mean',\n",
       " 'por',\n",
       " 'interesting',\n",
       " 'playing',\n",
       " 'pink',\n",
       " 'como',\n",
       " 'hit',\n",
       " 'three',\n",
       " 'thought',\n",
       " 'next',\n",
       " 'da',\n",
       " 'especially',\n",
       " 'need',\n",
       " 'soul',\n",
       " 'review',\n",
       " 'lo',\n",
       " 'favourite',\n",
       " 'high',\n",
       " 'less',\n",
       " 'course',\n",
       " 'listened',\n",
       " 'reason',\n",
       " 'real',\n",
       " 'idea',\n",
       " 'full',\n",
       " 'definitely',\n",
       " 'else',\n",
       " 'change',\n",
       " 'su',\n",
       " 'overall',\n",
       " 'later',\n",
       " 'zeppelin',\n",
       " 'yes',\n",
       " 'although',\n",
       " 'nice',\n",
       " 'truly',\n",
       " 'na',\n",
       " 'bowie',\n",
       " 'old',\n",
       " 'stuff',\n",
       " 'experience',\n",
       " 'sense',\n",
       " 'artist',\n",
       " 'simply',\n",
       " 'para',\n",
       " 'cover',\n",
       " 'rather',\n",
       " 'came',\n",
       " 'often',\n",
       " 'floyd',\n",
       " 'instrumental',\n",
       " 'close',\n",
       " 'hop',\n",
       " 'verse',\n",
       " 'released',\n",
       " 'm',\n",
       " 'absolutely',\n",
       " 'live',\n",
       " 'already',\n",
       " 'highlight',\n",
       " 'version',\n",
       " 'led',\n",
       " 'theme',\n",
       " 'brilliant',\n",
       " 'along',\n",
       " 'head',\n",
       " 'set',\n",
       " 'fantastic',\n",
       " 'quality',\n",
       " 'stone',\n",
       " 'must',\n",
       " 'il',\n",
       " 'al',\n",
       " 'perhaps',\n",
       " 'piano',\n",
       " 'tune',\n",
       " 'punk',\n",
       " 'throughout',\n",
       " 'cd',\n",
       " 'sort',\n",
       " 'tell',\n",
       " 'note',\n",
       " 'hip',\n",
       " 'keep',\n",
       " 'debut',\n",
       " 'stand',\n",
       " 'kanye',\n",
       " 'art',\n",
       " 'king',\n",
       " 'opinion',\n",
       " 'listener',\n",
       " 'making',\n",
       " 'found',\n",
       " 'completely',\n",
       " 'fun',\n",
       " 'group',\n",
       " 'excellent',\n",
       " 'john',\n",
       " 'unique',\n",
       " 'rap',\n",
       " 'used',\n",
       " 'cool',\n",
       " 'short',\n",
       " 'young',\n",
       " 'atmosphere',\n",
       " 'guy',\n",
       " 'story',\n",
       " 'final',\n",
       " 'w',\n",
       " 'wall',\n",
       " 'catchy',\n",
       " 'heart',\n",
       " 'epic',\n",
       " 'early',\n",
       " 'true',\n",
       " 'certainly',\n",
       " 'everyone',\n",
       " 'entire',\n",
       " 'original',\n",
       " 'simple',\n",
       " 'personal',\n",
       " 'done',\n",
       " 'hell',\n",
       " 'despite',\n",
       " 'progressive',\n",
       " 'four',\n",
       " 'influence',\n",
       " 'chorus',\n",
       " 'acoustic',\n",
       " 'feature',\n",
       " 'sometimes',\n",
       " 'shit',\n",
       " 'concept',\n",
       " 'look',\n",
       " 'opening',\n",
       " 'incredible',\n",
       " 'seem',\n",
       " 'dream',\n",
       " 'enjoy',\n",
       " 'run',\n",
       " 'perfectly',\n",
       " 'section',\n",
       " 'rating',\n",
       " 'number',\n",
       " 'instrument',\n",
       " 'example',\n",
       " 'son',\n",
       " 'friend',\n",
       " 'either',\n",
       " 'flow',\n",
       " 'played',\n",
       " 'singing',\n",
       " 'oh',\n",
       " 'est',\n",
       " 'fucking',\n",
       " 'previous',\n",
       " 'name',\n",
       " 'strong',\n",
       " 'ok',\n",
       " 'mood',\n",
       " 'plus',\n",
       " 'awesome',\n",
       " 'understand',\n",
       " 'turn',\n",
       " 'someone',\n",
       " 'god',\n",
       " 'career',\n",
       " 'performance',\n",
       " 'power',\n",
       " 'anyone',\n",
       " 'believe',\n",
       " 'night',\n",
       " 'getting',\n",
       " 'light',\n",
       " 'matter',\n",
       " 'che',\n",
       " 'este',\n",
       " 'hiphop',\n",
       " 'history',\n",
       " 'prog',\n",
       " 'wish',\n",
       " 'left',\n",
       " 'others',\n",
       " 'hand',\n",
       " 'boy',\n",
       " 'use',\n",
       " 'folk',\n",
       " 'finally',\n",
       " 'call',\n",
       " 'pero',\n",
       " 'try',\n",
       " 'songwriting',\n",
       " 'era',\n",
       " 'kid',\n",
       " 'trying',\n",
       " 'die',\n",
       " 'easily',\n",
       " 'lead',\n",
       " 'today',\n",
       " 'help',\n",
       " 'become',\n",
       " 'emotion',\n",
       " 'worth',\n",
       " 'noise',\n",
       " 'recorded',\n",
       " 'recording',\n",
       " 'mais',\n",
       " 'level',\n",
       " 'deep',\n",
       " 'guess',\n",
       " 'musician',\n",
       " 'important',\n",
       " 'bob',\n",
       " 'break',\n",
       " 'remember',\n",
       " 'instead',\n",
       " 'add',\n",
       " 'took',\n",
       " 'written',\n",
       " 'sample',\n",
       " 'rhythm',\n",
       " 'beginning',\n",
       " 'closer',\n",
       " 'five',\n",
       " 'girl',\n",
       " 'tone',\n",
       " 'mile',\n",
       " 'water',\n",
       " 'ballad',\n",
       " 'coming',\n",
       " 'radiohead',\n",
       " 'lost',\n",
       " 'studio',\n",
       " 'boring',\n",
       " 'effect',\n",
       " 'qui',\n",
       " 'moon',\n",
       " 'crimson',\n",
       " 'material',\n",
       " 'weird',\n",
       " 'emotional',\n",
       " 'cut',\n",
       " 'solid',\n",
       " 'talk',\n",
       " 'felt',\n",
       " 'form',\n",
       " 'fall',\n",
       " 'started',\n",
       " 'experimental',\n",
       " 'past',\n",
       " 'behind',\n",
       " 'couple',\n",
       " 'element',\n",
       " 'sabbath',\n",
       " 'sounding',\n",
       " 'z',\n",
       " 'mix',\n",
       " 'open',\n",
       " 'powerful',\n",
       " 'um',\n",
       " 'easy',\n",
       " 'lbum',\n",
       " 'genius',\n",
       " 'problem',\n",
       " 'talking',\n",
       " 'decade',\n",
       " 'paul',\n",
       " 'money',\n",
       " 'wrong',\n",
       " 'incredibly',\n",
       " 'similar',\n",
       " 'home',\n",
       " 'able',\n",
       " 'fit',\n",
       " 'damn',\n",
       " 'roll',\n",
       " 'hook',\n",
       " 'crazy',\n",
       " 'alone',\n",
       " 'hate',\n",
       " 'due',\n",
       " 'groove',\n",
       " 'mostly',\n",
       " 'begin',\n",
       " 'collection',\n",
       " 'funk',\n",
       " 'face',\n",
       " 'psychedelic',\n",
       " 'du',\n",
       " 'machine',\n",
       " 'slow',\n",
       " 'pure',\n",
       " 'given',\n",
       " 'road',\n",
       " 'electric',\n",
       " 'eye',\n",
       " 'late',\n",
       " 'main',\n",
       " 'lp',\n",
       " 'case',\n",
       " 'huge',\n",
       " 'hold',\n",
       " 'fine',\n",
       " 'create',\n",
       " 'went',\n",
       " 'wonder',\n",
       " 'yeah',\n",
       " 'ce',\n",
       " 'intro',\n",
       " 'human',\n",
       " 'anyway',\n",
       " 'wait',\n",
       " 'pa',\n",
       " 'low',\n",
       " 'saying',\n",
       " 'looking',\n",
       " 'particularly',\n",
       " 'maiden',\n",
       " 'house',\n",
       " 'writing',\n",
       " 'special',\n",
       " 'computer',\n",
       " 'tyler',\n",
       " 'wonderful',\n",
       " 'term',\n",
       " 'extremely',\n",
       " 'doubt',\n",
       " 'ear',\n",
       " 'fuck',\n",
       " 'une',\n",
       " 'nirvana',\n",
       " 'radio',\n",
       " 'strange',\n",
       " 'within',\n",
       " 'popular',\n",
       " 'th',\n",
       " 'exactly',\n",
       " 'arrangement',\n",
       " 'child',\n",
       " 'middle',\n",
       " 'melodic',\n",
       " 'care',\n",
       " 'future',\n",
       " 'white',\n",
       " 'composition',\n",
       " 'lack',\n",
       " 'david',\n",
       " 'general',\n",
       " 'chord',\n",
       " 'kendrick',\n",
       " 'called',\n",
       " 'slightly',\n",
       " 'seen',\n",
       " 'gone',\n",
       " 'stop',\n",
       " 'heaven',\n",
       " 'project',\n",
       " 'drumming',\n",
       " 'among',\n",
       " 'musically',\n",
       " 'clear',\n",
       " 'opener',\n",
       " 'absolute',\n",
       " 'possibly',\n",
       " 'member',\n",
       " 'energy',\n",
       " 'pick',\n",
       " 'filler',\n",
       " 'nearly',\n",
       " 'somewhat',\n",
       " 'instrumentation',\n",
       " 'todo',\n",
       " 'structure',\n",
       " 'hearing',\n",
       " 'woman',\n",
       " 'mi',\n",
       " 'string',\n",
       " 'effort',\n",
       " 'city',\n",
       " 'scene',\n",
       " 'attention',\n",
       " 'bring',\n",
       " 'step',\n",
       " 'enjoyable',\n",
       " 'sad',\n",
       " 'memorable',\n",
       " 'lyrical',\n",
       " 'b',\n",
       " 'write',\n",
       " 'impressive',\n",
       " 'fire',\n",
       " 'wanted',\n",
       " 'appreciate',\n",
       " 'red',\n",
       " 'robert',\n",
       " 'complete',\n",
       " 'sun',\n",
       " 'highly',\n",
       " 'forever',\n",
       " 'dog',\n",
       " 'period',\n",
       " 'essential',\n",
       " 'shine',\n",
       " 'key',\n",
       " 'upon',\n",
       " 'disc',\n",
       " 'dans',\n",
       " 'modern',\n",
       " 'across',\n",
       " 'towards',\n",
       " 'listens',\n",
       " 'nie',\n",
       " 'background',\n",
       " 'overrated',\n",
       " 'obviously',\n",
       " 'hour',\n",
       " 'complex',\n",
       " 'result',\n",
       " 'particular',\n",
       " 'keyboard',\n",
       " 'act',\n",
       " 'third',\n",
       " 'mark',\n",
       " 'sky',\n",
       " 'move',\n",
       " 'person',\n",
       " 'free',\n",
       " 'msica',\n",
       " 'honestly',\n",
       " 'near',\n",
       " 'car',\n",
       " 'raw',\n",
       " 'creative',\n",
       " 'double',\n",
       " 'beauty',\n",
       " 'basically',\n",
       " 'known',\n",
       " 'earlier',\n",
       " 'west',\n",
       " 'knew',\n",
       " 'jam',\n",
       " 'ya',\n",
       " 'country',\n",
       " 'whatever',\n",
       " 'finest',\n",
       " 'none',\n",
       " 'wind',\n",
       " 'beyond',\n",
       " 'build',\n",
       " 'somehow',\n",
       " 'edge',\n",
       " 'considered',\n",
       " 'drug',\n",
       " 'smith',\n",
       " 'standard',\n",
       " 'neil',\n",
       " 'giving',\n",
       " 'uma',\n",
       " 'soft',\n",
       " 'peak',\n",
       " 'state',\n",
       " 'dead',\n",
       " 'sing',\n",
       " 'joy',\n",
       " 'usually',\n",
       " 'leave',\n",
       " 'vibe',\n",
       " 'singer',\n",
       " 'blood',\n",
       " 'liked',\n",
       " 'loved',\n",
       " 'sus',\n",
       " 'became',\n",
       " 'ten',\n",
       " 'changed',\n",
       " 'ending',\n",
       " 'list',\n",
       " 'taste',\n",
       " 'bien',\n",
       " 'je',\n",
       " 'certain',\n",
       " 'kick',\n",
       " 'produced',\n",
       " 'space',\n",
       " 'mr',\n",
       " 'age',\n",
       " 'soundtrack',\n",
       " 'nature',\n",
       " 'taking',\n",
       " 'length',\n",
       " 'non',\n",
       " 'war',\n",
       " 'der',\n",
       " 'sin',\n",
       " 'worst',\n",
       " 'und',\n",
       " 'dance',\n",
       " 'rain',\n",
       " 'whether',\n",
       " 'possible',\n",
       " 'ride',\n",
       " 'hope',\n",
       " 'school',\n",
       " 'per',\n",
       " 'following',\n",
       " 'ambient',\n",
       " 'pour',\n",
       " 'ago',\n",
       " 'present',\n",
       " 'electronic',\n",
       " 'longer',\n",
       " 'type',\n",
       " 'par',\n",
       " 'totally',\n",
       " 'consider',\n",
       " 'clearly',\n",
       " 'compared',\n",
       " 'ser',\n",
       " 'rolling',\n",
       " 'talent',\n",
       " 'fully',\n",
       " 'touch',\n",
       " 'mention',\n",
       " 'street',\n",
       " 'soon',\n",
       " 'obvious',\n",
       " 'prefer',\n",
       " 'finish',\n",
       " 'gave',\n",
       " 'uno',\n",
       " 'frank',\n",
       " 'except',\n",
       " 'george',\n",
       " 'created',\n",
       " 'page',\n",
       " 'read',\n",
       " 'several',\n",
       " 'approach',\n",
       " 'n',\n",
       " 'lyrically',\n",
       " 'direction',\n",
       " 'weak',\n",
       " 'imagine',\n",
       " 'nevermind',\n",
       " 'fast',\n",
       " 'etc',\n",
       " 'funky',\n",
       " 'intense',\n",
       " 'wave',\n",
       " 'movie',\n",
       " 'contains',\n",
       " 'film',\n",
       " 'hendrix',\n",
       " 'american',\n",
       " 'sweet',\n",
       " 'brings',\n",
       " 'return',\n",
       " 'describe',\n",
       " 'amount',\n",
       " 'happy',\n",
       " 'follow',\n",
       " 'hey',\n",
       " 'rapper',\n",
       " 'banda',\n",
       " 'apart',\n",
       " 'taken',\n",
       " 'seriously',\n",
       " 'davis',\n",
       " 'straight',\n",
       " 'thinking',\n",
       " 'remains',\n",
       " 'unlike',\n",
       " 'synth',\n",
       " 'inspired',\n",
       " 'com',\n",
       " 'famous',\n",
       " 'lennon',\n",
       " 'baby',\n",
       " 'ne',\n",
       " 'game',\n",
       " 'living',\n",
       " 'master',\n",
       " 'buy',\n",
       " 'bitch',\n",
       " 'sonic',\n",
       " 'decent',\n",
       " 'tom',\n",
       " 'journey',\n",
       " 'consistent',\n",
       " 'bought',\n",
       " 'cry',\n",
       " 'picture',\n",
       " 'major',\n",
       " 'revolver',\n",
       " 'memory',\n",
       " 'canciones',\n",
       " 'loud',\n",
       " 'gorgeous',\n",
       " 'tempo',\n",
       " 'discography',\n",
       " 'question',\n",
       " 'character',\n",
       " 'job',\n",
       " 'aspect',\n",
       " 'ability',\n",
       " 'station',\n",
       " 'te',\n",
       " 'wild',\n",
       " 'personally',\n",
       " 'aside',\n",
       " 'cold',\n",
       " 'sur',\n",
       " 'surprise',\n",
       " 'swan',\n",
       " 'iron',\n",
       " 'biggest',\n",
       " 'fresh',\n",
       " 'room',\n",
       " 'issue',\n",
       " 'message',\n",
       " 'reach',\n",
       " 'difficult',\n",
       " 'grunge',\n",
       " 'starting',\n",
       " 'offer',\n",
       " 'thrash',\n",
       " 'honest',\n",
       " 'vision',\n",
       " 'blonde',\n",
       " 'success',\n",
       " 'instrumentals',\n",
       " 'harmony',\n",
       " 'alternative',\n",
       " 'cest',\n",
       " 'meaning',\n",
       " 'relationship',\n",
       " 'avec',\n",
       " 'pi',\n",
       " 'spirit',\n",
       " 'deserves',\n",
       " 'annoying',\n",
       " 'check',\n",
       " 'mother',\n",
       " 'decided',\n",
       " 'month',\n",
       " 'average',\n",
       " 'jest',\n",
       " 'deal',\n",
       " 'genesis',\n",
       " 'funny',\n",
       " 'accessible',\n",
       " 'including',\n",
       " 'coltrane',\n",
       " 'ma',\n",
       " 'context',\n",
       " 'immediately',\n",
       " 'player',\n",
       " 'holy',\n",
       " 'entirely',\n",
       " 'indie',\n",
       " 'haunting',\n",
       " 'esta',\n",
       " 'focus',\n",
       " 'unfortunately',\n",
       " 'followed',\n",
       " 'curtis',\n",
       " 'magic',\n",
       " 'sounded',\n",
       " 'becomes',\n",
       " 'animal',\n",
       " 'expect',\n",
       " 'warm',\n",
       " 'wrote',\n",
       " 'odd',\n",
       " 'pepper',\n",
       " 'individual',\n",
       " 'statement',\n",
       " 'based',\n",
       " 'au',\n",
       " 'massive',\n",
       " 'fade',\n",
       " 'hill',\n",
       " 'turned',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'indeed',\n",
       " 'sings',\n",
       " 'stay',\n",
       " 'river',\n",
       " 'inside',\n",
       " 'diamond',\n",
       " 'manages',\n",
       " 'no',\n",
       " 'serious',\n",
       " 'rapping',\n",
       " 'mccartney',\n",
       " 'fantasy',\n",
       " 'percussion',\n",
       " 'nowhere',\n",
       " 'tour',\n",
       " 'seemed',\n",
       " 'repetitive',\n",
       " 'earth',\n",
       " 'killer',\n",
       " 'influential',\n",
       " 'forget',\n",
       " 'plant',\n",
       " 'drive',\n",
       " 'kill',\n",
       " 'latter',\n",
       " 'mainstream',\n",
       " 'book',\n",
       " 'outside',\n",
       " 'small',\n",
       " 'tout',\n",
       " 'variety',\n",
       " 'bruce',\n",
       " 'praise',\n",
       " 'sex',\n",
       " 'technical',\n",
       " 'synths',\n",
       " 'l',\n",
       " 'carry',\n",
       " 'ha',\n",
       " 'chance',\n",
       " 'perfection',\n",
       " 'delivery',\n",
       " 'stick',\n",
       " 'mentioned',\n",
       " 'somewhere',\n",
       " 'actual',\n",
       " 'guitarist',\n",
       " 'saw',\n",
       " 'running',\n",
       " 'recommend',\n",
       " 'producer',\n",
       " 'eventually',\n",
       " 'order',\n",
       " 'ocean',\n",
       " 'self',\n",
       " 'vinyl',\n",
       " 'organ',\n",
       " 'attempt',\n",
       " 'doom',\n",
       " 'muy',\n",
       " 'slowly',\n",
       " 'tried',\n",
       " 'loveless',\n",
       " 'sea',\n",
       " 'brain',\n",
       " 'born',\n",
       " 'evil',\n",
       " 'trip',\n",
       " 'lady',\n",
       " 'do',\n",
       " 'session',\n",
       " 'okay',\n",
       " 'front',\n",
       " 'pleasure',\n",
       " 'closing',\n",
       " 'echo',\n",
       " 'co',\n",
       " 'hype',\n",
       " 'st',\n",
       " 'admit',\n",
       " 'interlude',\n",
       " 'atmospheric',\n",
       " 'pixy',\n",
       " 'dynamic',\n",
       " 'content',\n",
       " 'century',\n",
       " 'eno',\n",
       " 'rate',\n",
       " 'cancin',\n",
       " 'detail',\n",
       " 'drummer',\n",
       " 'pain',\n",
       " 'grand',\n",
       " 'lie',\n",
       " 'higher',\n",
       " 'realize',\n",
       " 'mingus',\n",
       " 'considering',\n",
       " 'influenced',\n",
       " 'abbey',\n",
       " 'michael',\n",
       " 'transition',\n",
       " 'filled',\n",
       " 'van',\n",
       " 'green',\n",
       " 'mejor',\n",
       " 'comparison',\n",
       " 'artistic',\n",
       " 'needed',\n",
       " 'exception',\n",
       " 'ian',\n",
       " 'subject',\n",
       " 'appeal',\n",
       " 'bar',\n",
       " 'force',\n",
       " 'fusion',\n",
       " 'impossible',\n",
       " 'rocker',\n",
       " 'mine',\n",
       " 'angel',\n",
       " 'steve',\n",
       " 'brother',\n",
       " 'smooth',\n",
       " 'pull',\n",
       " 'ahead',\n",
       " 'rubber',\n",
       " 'backing',\n",
       " 'leaf',\n",
       " 'creating',\n",
       " 'generation',\n",
       " 'otherwise',\n",
       " 'super',\n",
       " 'kanyes',\n",
       " 'reminds',\n",
       " 'algo',\n",
       " 'as',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37bb05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w2v = data['Cleaned_Review'].apply(lambda x: document_vector(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_w2v\n",
    "# #save in a csv\n",
    "# # Convert the Series of numpy arrays to a DataFrame\n",
    "# X_w2v_df = X_w2v.apply(pd.Series)\n",
    "# # Optionally, add the index or an identifier if needed\n",
    "# X_w2v_df.to_csv('./dataset/X_w2v_vectors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123d3b79",
   "metadata": {},
   "source": [
    "## splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "99568a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f062",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(alpha=1.0,solver='lsqr')\n",
    "    # 'RandomForestRegressor':RandomForestRegressor(),\n",
    "    # 'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    # 'SVR':SVR(),\n",
    "    # 'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    # 'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    # 'XGBRegressor':XGBRegressor(),\n",
    "    # 'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "695a124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "metrics_list = []\n",
    "\n",
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7625567b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.817187</td>\n",
       "      <td>0.903984</td>\n",
       "      <td>-0.090847</td>\n",
       "      <td>0.690256</td>\n",
       "      <td>0.216402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.476026</td>\n",
       "      <td>0.689946</td>\n",
       "      <td>0.364562</td>\n",
       "      <td>0.510050</td>\n",
       "      <td>0.177092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0  LinearRegression  0.817187  0.903984 -0.090847  0.690256  0.216402\n",
       "1             Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2             Ridge  0.476026  0.689946  0.364562  0.510050  0.177092"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68306cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4786890035560246\n",
      "R2: 0.3610068961991709\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9a2e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter review: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Clean the review text\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m clean_data \u001b[38;5;241m=\u001b[39m preprocess_text(text)  \u001b[38;5;66;03m# This should return a cleaned string\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Vectorize using the already trained vectorizer (do NOT use fit_transform)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform([clean_data])  \u001b[38;5;66;03m# Wrap in a list to avoid error\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "text = input(\"Enter review: \")\n",
    "\n",
    "# Clean the review text\n",
    "clean_data = preprocess_text(text)  # This should return a cleaned string\n",
    "\n",
    "# Vectorize using the already trained vectorizer (do NOT use fit_transform)\n",
    "X = tfidf_vectorizer.transform([clean_data])  # Wrap in a list to avoid error\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_rating = model.predict(X)\n",
    "\n",
    "# Output the result\n",
    "print(f\"The predicted rating for the review '{text}' is: {predicted_rating[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4b6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Pipeline Performance:\n",
      "MSE: 0.5941\n",
      "MAE: 0.5827\n",
      "R2: 0.2069\n",
      "RMSE: 0.7708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Enhanced pipeline with feature selection\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(with_mean=False),  # Important for sparse matrices\n",
    "    SelectKBest(f_regression, k=5000),\n",
    "    GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nEnhanced Pipeline Performance:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
