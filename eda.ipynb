{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af24d0",
   "metadata": {},
   "source": [
    "## Exploraty Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da38a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  i think i actually under-rate ok computer if a...     5.0\n",
       "1  i get why radiohead rub a lot of people the wr...     5.0\n",
       "2  i would like to think i am good about not lett...     4.5\n",
       "3  there are radiohead devotees like there were o...     4.0\n",
       "4  i wrote a shining excellent review for this al...     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/music_album_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 80271\n",
      "Rating distribution:\n",
      "Rating\n",
      "5.0    29534\n",
      "4.5    17793\n",
      "4.0    14213\n",
      "3.5     7048\n",
      "3.0     4430\n",
      "2.5     2210\n",
      "2.0     1396\n",
      "1.5      640\n",
      "1.0      525\n",
      "0.5      398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(f\"Rating distribution:\\n{df['Rating'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb8eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review      26\n",
       "Rating    2084\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f313865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d4e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tokenizes the text,lowercase the text, remove stopwords, and lemmatize the text \n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)  # Keep !? for sentiment\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>think actually underrate ok computer anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>get radiohead rub lot people wrong way lot peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>would like think good letting wider critical w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>radiohead devotee like bowie devotee find unex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wrote shining excellent review album browser w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  \\\n",
       "0  i think i actually under-rate ok computer if a...     5.0   \n",
       "1  i get why radiohead rub a lot of people the wr...     5.0   \n",
       "2  i would like to think i am good about not lett...     4.5   \n",
       "3  there are radiohead devotees like there were o...     4.0   \n",
       "4  i wrote a shining excellent review for this al...     5.0   \n",
       "\n",
       "                                      Cleaned_Review  \n",
       "0  think actually underrate ok computer anything ...  \n",
       "1  get radiohead rub lot people wrong way lot peo...  \n",
       "2  would like think good letting wider critical w...  \n",
       "3  radiohead devotee like bowie devotee find unex...  \n",
       "4  wrote shining excellent review album browser w...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'] = df['Review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f5a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7734a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb80a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the empty strings in cleaned_review column\n",
    "df = df[df['Cleaned_Review'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0293cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f3af1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_csv \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/cleaned_music_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_csv = df.to_csv('./dataset/cleaned_music_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dc66420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review            0\n",
       "Rating            0\n",
       "Cleaned_Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/cleaned_music_reviews.csv')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54e8e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2),\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Review'])\n",
    "vocab = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51948a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Assuming 'data' is your DataFrame and 'Cleaned_Review' is the column with tokenized text (as lists of words)\n",
    "# If not tokenized, tokenize first:\n",
    "data['tokens'] = data['Cleaned_Review'].apply(lambda x: x.split())\n",
    "\n",
    "# Train Word2Vec model (or load a pre-trained one)\n",
    "w2v_model = Word2Vec(sentences=data['tokens'], vector_size=100, window=5, min_count=5, workers=4)\n",
    "\n",
    "def document_vector(word_list):\n",
    "    # Remove out-of-vocabulary words\n",
    "    word_list = [word for word in word_list if word in w2v_model.wv.index_to_key]\n",
    "    if len(word_list) == 0:\n",
    "        return np.zeros(100)\n",
    "    return np.mean(w2v_model.wv[word_list], axis=0)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9fcdaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['album',\n",
       " 'song',\n",
       " 'one',\n",
       " 'like',\n",
       " 'de',\n",
       " 'track',\n",
       " 'time',\n",
       " 'music',\n",
       " 'sound',\n",
       " 'really',\n",
       " 'best',\n",
       " 'would',\n",
       " 'la',\n",
       " '!',\n",
       " 'great',\n",
       " 'good',\n",
       " 'que',\n",
       " '?',\n",
       " 'band',\n",
       " 'rock',\n",
       " 'even',\n",
       " 'first',\n",
       " 'much',\n",
       " 'get',\n",
       " 'record',\n",
       " 'still',\n",
       " 'make',\n",
       " 'love',\n",
       " 'guitar',\n",
       " 'way',\n",
       " 'ever',\n",
       " 'e',\n",
       " 'feel',\n",
       " 'well',\n",
       " 'think',\n",
       " 'thing',\n",
       " 'also',\n",
       " 'listen',\n",
       " 'come',\n",
       " 'en',\n",
       " 'could',\n",
       " 'know',\n",
       " 'lyric',\n",
       " 'un',\n",
       " 'vocal',\n",
       " 'say',\n",
       " 'never',\n",
       " 'something',\n",
       " 'year',\n",
       " 'work',\n",
       " 'every',\n",
       " 'el',\n",
       " 'many',\n",
       " 'two',\n",
       " 'though',\n",
       " 'go',\n",
       " 'favorite',\n",
       " 'better',\n",
       " 'metal',\n",
       " 'life',\n",
       " 'people',\n",
       " 'back',\n",
       " 'heard',\n",
       " 'lot',\n",
       " 'end',\n",
       " 'part',\n",
       " 'classic',\n",
       " 'pretty',\n",
       " 'little',\n",
       " 'le',\n",
       " 'take',\n",
       " 'going',\n",
       " 'bit',\n",
       " 'side',\n",
       " 'another',\n",
       " 'new',\n",
       " 'long',\n",
       " 'made',\n",
       " 'day',\n",
       " 'minute',\n",
       " 'probably',\n",
       " 'man',\n",
       " 'got',\n",
       " 'kind',\n",
       " 'perfect',\n",
       " 'quite',\n",
       " 'solo',\n",
       " 'always',\n",
       " 'pop',\n",
       " 'give',\n",
       " 'point',\n",
       " 'want',\n",
       " 'blue',\n",
       " 'see',\n",
       " 'whole',\n",
       " 'hard',\n",
       " 'listening',\n",
       " 'world',\n",
       " 'almost',\n",
       " 'moment',\n",
       " 'start',\n",
       " 'second',\n",
       " 'yet',\n",
       " 'jazz',\n",
       " 'right',\n",
       " 'fan',\n",
       " 'una',\n",
       " 'se',\n",
       " 'production',\n",
       " 'find',\n",
       " 'amazing',\n",
       " 'con',\n",
       " 'release',\n",
       " 'last',\n",
       " 'u',\n",
       " 'riff',\n",
       " 'beat',\n",
       " 'beautiful',\n",
       " 'death',\n",
       " 'everything',\n",
       " 'nothing',\n",
       " 'different',\n",
       " 'greatest',\n",
       " 'far',\n",
       " 'black',\n",
       " 'dark',\n",
       " 'drum',\n",
       " 'actually',\n",
       " 'beatles',\n",
       " 'disco',\n",
       " 'los',\n",
       " 'hear',\n",
       " 'let',\n",
       " 'del',\n",
       " 'without',\n",
       " 'said',\n",
       " 'around',\n",
       " 'anything',\n",
       " 'single',\n",
       " 'voice',\n",
       " 'put',\n",
       " 'title',\n",
       " 'least',\n",
       " 'maybe',\n",
       " 'bad',\n",
       " 'masterpiece',\n",
       " 'enough',\n",
       " 'melody',\n",
       " 'bass',\n",
       " 'musical',\n",
       " 'mind',\n",
       " 'star',\n",
       " 'dylan',\n",
       " 'sure',\n",
       " 'however',\n",
       " 'et',\n",
       " 'piece',\n",
       " 'top',\n",
       " 'line',\n",
       " 'rest',\n",
       " 'style',\n",
       " 'genre',\n",
       " 'play',\n",
       " 'heavy',\n",
       " 'fact',\n",
       " 'may',\n",
       " 'since',\n",
       " 'half',\n",
       " 'word',\n",
       " 'place',\n",
       " 'big',\n",
       " 'feeling',\n",
       " 'away',\n",
       " 'might',\n",
       " 'together',\n",
       " 'si',\n",
       " 'di',\n",
       " 'show',\n",
       " 'seems',\n",
       " 'mean',\n",
       " 'por',\n",
       " 'interesting',\n",
       " 'playing',\n",
       " 'pink',\n",
       " 'como',\n",
       " 'hit',\n",
       " 'three',\n",
       " 'thought',\n",
       " 'next',\n",
       " 'da',\n",
       " 'especially',\n",
       " 'need',\n",
       " 'soul',\n",
       " 'review',\n",
       " 'lo',\n",
       " 'favourite',\n",
       " 'high',\n",
       " 'less',\n",
       " 'course',\n",
       " 'listened',\n",
       " 'reason',\n",
       " 'real',\n",
       " 'idea',\n",
       " 'full',\n",
       " 'definitely',\n",
       " 'else',\n",
       " 'change',\n",
       " 'su',\n",
       " 'overall',\n",
       " 'later',\n",
       " 'zeppelin',\n",
       " 'yes',\n",
       " 'although',\n",
       " 'nice',\n",
       " 'truly',\n",
       " 'na',\n",
       " 'bowie',\n",
       " 'old',\n",
       " 'stuff',\n",
       " 'experience',\n",
       " 'sense',\n",
       " 'artist',\n",
       " 'simply',\n",
       " 'para',\n",
       " 'cover',\n",
       " 'rather',\n",
       " 'came',\n",
       " 'often',\n",
       " 'floyd',\n",
       " 'instrumental',\n",
       " 'close',\n",
       " 'hop',\n",
       " 'verse',\n",
       " 'released',\n",
       " 'm',\n",
       " 'absolutely',\n",
       " 'live',\n",
       " 'already',\n",
       " 'highlight',\n",
       " 'version',\n",
       " 'led',\n",
       " 'theme',\n",
       " 'brilliant',\n",
       " 'along',\n",
       " 'head',\n",
       " 'set',\n",
       " 'fantastic',\n",
       " 'quality',\n",
       " 'stone',\n",
       " 'must',\n",
       " 'il',\n",
       " 'al',\n",
       " 'perhaps',\n",
       " 'piano',\n",
       " 'tune',\n",
       " 'punk',\n",
       " 'throughout',\n",
       " 'cd',\n",
       " 'sort',\n",
       " 'tell',\n",
       " 'note',\n",
       " 'hip',\n",
       " 'keep',\n",
       " 'debut',\n",
       " 'stand',\n",
       " 'kanye',\n",
       " 'art',\n",
       " 'king',\n",
       " 'opinion',\n",
       " 'listener',\n",
       " 'making',\n",
       " 'found',\n",
       " 'completely',\n",
       " 'fun',\n",
       " 'group',\n",
       " 'excellent',\n",
       " 'john',\n",
       " 'unique',\n",
       " 'rap',\n",
       " 'used',\n",
       " 'cool',\n",
       " 'short',\n",
       " 'young',\n",
       " 'atmosphere',\n",
       " 'guy',\n",
       " 'story',\n",
       " 'final',\n",
       " 'w',\n",
       " 'wall',\n",
       " 'catchy',\n",
       " 'heart',\n",
       " 'epic',\n",
       " 'early',\n",
       " 'true',\n",
       " 'certainly',\n",
       " 'everyone',\n",
       " 'entire',\n",
       " 'original',\n",
       " 'simple',\n",
       " 'personal',\n",
       " 'done',\n",
       " 'hell',\n",
       " 'despite',\n",
       " 'progressive',\n",
       " 'four',\n",
       " 'influence',\n",
       " 'chorus',\n",
       " 'acoustic',\n",
       " 'feature',\n",
       " 'sometimes',\n",
       " 'shit',\n",
       " 'concept',\n",
       " 'look',\n",
       " 'opening',\n",
       " 'incredible',\n",
       " 'seem',\n",
       " 'dream',\n",
       " 'enjoy',\n",
       " 'run',\n",
       " 'perfectly',\n",
       " 'section',\n",
       " 'rating',\n",
       " 'number',\n",
       " 'instrument',\n",
       " 'example',\n",
       " 'son',\n",
       " 'friend',\n",
       " 'either',\n",
       " 'flow',\n",
       " 'played',\n",
       " 'singing',\n",
       " 'oh',\n",
       " 'est',\n",
       " 'fucking',\n",
       " 'previous',\n",
       " 'name',\n",
       " 'strong',\n",
       " 'ok',\n",
       " 'mood',\n",
       " 'plus',\n",
       " 'awesome',\n",
       " 'understand',\n",
       " 'turn',\n",
       " 'someone',\n",
       " 'god',\n",
       " 'career',\n",
       " 'performance',\n",
       " 'power',\n",
       " 'anyone',\n",
       " 'believe',\n",
       " 'night',\n",
       " 'getting',\n",
       " 'light',\n",
       " 'matter',\n",
       " 'che',\n",
       " 'este',\n",
       " 'hiphop',\n",
       " 'history',\n",
       " 'prog',\n",
       " 'wish',\n",
       " 'left',\n",
       " 'others',\n",
       " 'hand',\n",
       " 'boy',\n",
       " 'use',\n",
       " 'folk',\n",
       " 'finally',\n",
       " 'call',\n",
       " 'pero',\n",
       " 'try',\n",
       " 'songwriting',\n",
       " 'era',\n",
       " 'kid',\n",
       " 'trying',\n",
       " 'die',\n",
       " 'easily',\n",
       " 'lead',\n",
       " 'today',\n",
       " 'help',\n",
       " 'become',\n",
       " 'emotion',\n",
       " 'worth',\n",
       " 'noise',\n",
       " 'recorded',\n",
       " 'recording',\n",
       " 'mais',\n",
       " 'level',\n",
       " 'deep',\n",
       " 'guess',\n",
       " 'musician',\n",
       " 'important',\n",
       " 'bob',\n",
       " 'break',\n",
       " 'remember',\n",
       " 'instead',\n",
       " 'add',\n",
       " 'took',\n",
       " 'written',\n",
       " 'sample',\n",
       " 'rhythm',\n",
       " 'beginning',\n",
       " 'closer',\n",
       " 'five',\n",
       " 'girl',\n",
       " 'tone',\n",
       " 'mile',\n",
       " 'water',\n",
       " 'ballad',\n",
       " 'coming',\n",
       " 'radiohead',\n",
       " 'lost',\n",
       " 'studio',\n",
       " 'boring',\n",
       " 'effect',\n",
       " 'qui',\n",
       " 'moon',\n",
       " 'crimson',\n",
       " 'material',\n",
       " 'weird',\n",
       " 'emotional',\n",
       " 'cut',\n",
       " 'solid',\n",
       " 'talk',\n",
       " 'felt',\n",
       " 'form',\n",
       " 'fall',\n",
       " 'started',\n",
       " 'experimental',\n",
       " 'past',\n",
       " 'behind',\n",
       " 'couple',\n",
       " 'element',\n",
       " 'sabbath',\n",
       " 'sounding',\n",
       " 'z',\n",
       " 'mix',\n",
       " 'open',\n",
       " 'powerful',\n",
       " 'um',\n",
       " 'easy',\n",
       " 'lbum',\n",
       " 'genius',\n",
       " 'problem',\n",
       " 'talking',\n",
       " 'decade',\n",
       " 'paul',\n",
       " 'money',\n",
       " 'wrong',\n",
       " 'incredibly',\n",
       " 'similar',\n",
       " 'home',\n",
       " 'able',\n",
       " 'fit',\n",
       " 'damn',\n",
       " 'roll',\n",
       " 'hook',\n",
       " 'crazy',\n",
       " 'alone',\n",
       " 'hate',\n",
       " 'due',\n",
       " 'groove',\n",
       " 'mostly',\n",
       " 'begin',\n",
       " 'collection',\n",
       " 'funk',\n",
       " 'face',\n",
       " 'psychedelic',\n",
       " 'du',\n",
       " 'machine',\n",
       " 'slow',\n",
       " 'pure',\n",
       " 'given',\n",
       " 'road',\n",
       " 'electric',\n",
       " 'eye',\n",
       " 'late',\n",
       " 'main',\n",
       " 'lp',\n",
       " 'case',\n",
       " 'huge',\n",
       " 'hold',\n",
       " 'fine',\n",
       " 'create',\n",
       " 'went',\n",
       " 'wonder',\n",
       " 'yeah',\n",
       " 'ce',\n",
       " 'intro',\n",
       " 'human',\n",
       " 'anyway',\n",
       " 'wait',\n",
       " 'pa',\n",
       " 'low',\n",
       " 'saying',\n",
       " 'looking',\n",
       " 'particularly',\n",
       " 'maiden',\n",
       " 'house',\n",
       " 'writing',\n",
       " 'special',\n",
       " 'computer',\n",
       " 'tyler',\n",
       " 'wonderful',\n",
       " 'term',\n",
       " 'extremely',\n",
       " 'doubt',\n",
       " 'ear',\n",
       " 'fuck',\n",
       " 'une',\n",
       " 'nirvana',\n",
       " 'radio',\n",
       " 'strange',\n",
       " 'within',\n",
       " 'popular',\n",
       " 'th',\n",
       " 'exactly',\n",
       " 'arrangement',\n",
       " 'child',\n",
       " 'middle',\n",
       " 'melodic',\n",
       " 'care',\n",
       " 'future',\n",
       " 'white',\n",
       " 'composition',\n",
       " 'lack',\n",
       " 'david',\n",
       " 'general',\n",
       " 'chord',\n",
       " 'kendrick',\n",
       " 'called',\n",
       " 'slightly',\n",
       " 'seen',\n",
       " 'gone',\n",
       " 'stop',\n",
       " 'heaven',\n",
       " 'project',\n",
       " 'drumming',\n",
       " 'among',\n",
       " 'musically',\n",
       " 'clear',\n",
       " 'opener',\n",
       " 'absolute',\n",
       " 'possibly',\n",
       " 'member',\n",
       " 'energy',\n",
       " 'pick',\n",
       " 'filler',\n",
       " 'nearly',\n",
       " 'somewhat',\n",
       " 'instrumentation',\n",
       " 'todo',\n",
       " 'structure',\n",
       " 'hearing',\n",
       " 'woman',\n",
       " 'mi',\n",
       " 'string',\n",
       " 'effort',\n",
       " 'city',\n",
       " 'scene',\n",
       " 'attention',\n",
       " 'bring',\n",
       " 'step',\n",
       " 'enjoyable',\n",
       " 'sad',\n",
       " 'memorable',\n",
       " 'lyrical',\n",
       " 'b',\n",
       " 'write',\n",
       " 'impressive',\n",
       " 'fire',\n",
       " 'wanted',\n",
       " 'appreciate',\n",
       " 'red',\n",
       " 'robert',\n",
       " 'complete',\n",
       " 'sun',\n",
       " 'highly',\n",
       " 'forever',\n",
       " 'dog',\n",
       " 'period',\n",
       " 'essential',\n",
       " 'shine',\n",
       " 'key',\n",
       " 'upon',\n",
       " 'disc',\n",
       " 'dans',\n",
       " 'modern',\n",
       " 'across',\n",
       " 'towards',\n",
       " 'listens',\n",
       " 'nie',\n",
       " 'background',\n",
       " 'overrated',\n",
       " 'obviously',\n",
       " 'hour',\n",
       " 'complex',\n",
       " 'result',\n",
       " 'particular',\n",
       " 'keyboard',\n",
       " 'act',\n",
       " 'third',\n",
       " 'mark',\n",
       " 'sky',\n",
       " 'move',\n",
       " 'person',\n",
       " 'free',\n",
       " 'msica',\n",
       " 'honestly',\n",
       " 'near',\n",
       " 'car',\n",
       " 'raw',\n",
       " 'creative',\n",
       " 'double',\n",
       " 'beauty',\n",
       " 'basically',\n",
       " 'known',\n",
       " 'earlier',\n",
       " 'west',\n",
       " 'knew',\n",
       " 'jam',\n",
       " 'ya',\n",
       " 'country',\n",
       " 'whatever',\n",
       " 'finest',\n",
       " 'none',\n",
       " 'wind',\n",
       " 'beyond',\n",
       " 'build',\n",
       " 'somehow',\n",
       " 'edge',\n",
       " 'considered',\n",
       " 'drug',\n",
       " 'smith',\n",
       " 'standard',\n",
       " 'neil',\n",
       " 'giving',\n",
       " 'uma',\n",
       " 'soft',\n",
       " 'peak',\n",
       " 'state',\n",
       " 'dead',\n",
       " 'sing',\n",
       " 'joy',\n",
       " 'usually',\n",
       " 'leave',\n",
       " 'vibe',\n",
       " 'singer',\n",
       " 'blood',\n",
       " 'liked',\n",
       " 'loved',\n",
       " 'sus',\n",
       " 'became',\n",
       " 'ten',\n",
       " 'changed',\n",
       " 'ending',\n",
       " 'list',\n",
       " 'taste',\n",
       " 'bien',\n",
       " 'je',\n",
       " 'certain',\n",
       " 'kick',\n",
       " 'produced',\n",
       " 'space',\n",
       " 'mr',\n",
       " 'age',\n",
       " 'soundtrack',\n",
       " 'nature',\n",
       " 'taking',\n",
       " 'length',\n",
       " 'non',\n",
       " 'war',\n",
       " 'der',\n",
       " 'sin',\n",
       " 'worst',\n",
       " 'und',\n",
       " 'dance',\n",
       " 'rain',\n",
       " 'whether',\n",
       " 'possible',\n",
       " 'ride',\n",
       " 'hope',\n",
       " 'school',\n",
       " 'per',\n",
       " 'following',\n",
       " 'ambient',\n",
       " 'pour',\n",
       " 'ago',\n",
       " 'present',\n",
       " 'electronic',\n",
       " 'longer',\n",
       " 'type',\n",
       " 'par',\n",
       " 'totally',\n",
       " 'consider',\n",
       " 'clearly',\n",
       " 'compared',\n",
       " 'ser',\n",
       " 'rolling',\n",
       " 'talent',\n",
       " 'fully',\n",
       " 'touch',\n",
       " 'mention',\n",
       " 'street',\n",
       " 'soon',\n",
       " 'obvious',\n",
       " 'prefer',\n",
       " 'finish',\n",
       " 'gave',\n",
       " 'uno',\n",
       " 'frank',\n",
       " 'except',\n",
       " 'george',\n",
       " 'created',\n",
       " 'page',\n",
       " 'read',\n",
       " 'several',\n",
       " 'approach',\n",
       " 'n',\n",
       " 'lyrically',\n",
       " 'direction',\n",
       " 'weak',\n",
       " 'imagine',\n",
       " 'nevermind',\n",
       " 'fast',\n",
       " 'etc',\n",
       " 'funky',\n",
       " 'intense',\n",
       " 'wave',\n",
       " 'movie',\n",
       " 'contains',\n",
       " 'film',\n",
       " 'hendrix',\n",
       " 'american',\n",
       " 'sweet',\n",
       " 'brings',\n",
       " 'return',\n",
       " 'describe',\n",
       " 'amount',\n",
       " 'happy',\n",
       " 'follow',\n",
       " 'hey',\n",
       " 'rapper',\n",
       " 'banda',\n",
       " 'apart',\n",
       " 'taken',\n",
       " 'seriously',\n",
       " 'davis',\n",
       " 'straight',\n",
       " 'thinking',\n",
       " 'remains',\n",
       " 'unlike',\n",
       " 'synth',\n",
       " 'inspired',\n",
       " 'com',\n",
       " 'famous',\n",
       " 'lennon',\n",
       " 'baby',\n",
       " 'ne',\n",
       " 'game',\n",
       " 'living',\n",
       " 'master',\n",
       " 'buy',\n",
       " 'bitch',\n",
       " 'sonic',\n",
       " 'decent',\n",
       " 'tom',\n",
       " 'journey',\n",
       " 'consistent',\n",
       " 'bought',\n",
       " 'cry',\n",
       " 'picture',\n",
       " 'major',\n",
       " 'revolver',\n",
       " 'memory',\n",
       " 'canciones',\n",
       " 'loud',\n",
       " 'gorgeous',\n",
       " 'tempo',\n",
       " 'discography',\n",
       " 'question',\n",
       " 'character',\n",
       " 'job',\n",
       " 'aspect',\n",
       " 'ability',\n",
       " 'station',\n",
       " 'te',\n",
       " 'wild',\n",
       " 'personally',\n",
       " 'aside',\n",
       " 'cold',\n",
       " 'sur',\n",
       " 'surprise',\n",
       " 'swan',\n",
       " 'iron',\n",
       " 'biggest',\n",
       " 'fresh',\n",
       " 'room',\n",
       " 'issue',\n",
       " 'message',\n",
       " 'reach',\n",
       " 'difficult',\n",
       " 'grunge',\n",
       " 'starting',\n",
       " 'offer',\n",
       " 'thrash',\n",
       " 'honest',\n",
       " 'vision',\n",
       " 'blonde',\n",
       " 'success',\n",
       " 'instrumentals',\n",
       " 'harmony',\n",
       " 'alternative',\n",
       " 'cest',\n",
       " 'meaning',\n",
       " 'relationship',\n",
       " 'avec',\n",
       " 'pi',\n",
       " 'spirit',\n",
       " 'deserves',\n",
       " 'annoying',\n",
       " 'check',\n",
       " 'mother',\n",
       " 'decided',\n",
       " 'month',\n",
       " 'average',\n",
       " 'jest',\n",
       " 'deal',\n",
       " 'genesis',\n",
       " 'funny',\n",
       " 'accessible',\n",
       " 'including',\n",
       " 'coltrane',\n",
       " 'ma',\n",
       " 'context',\n",
       " 'immediately',\n",
       " 'player',\n",
       " 'holy',\n",
       " 'entirely',\n",
       " 'indie',\n",
       " 'haunting',\n",
       " 'esta',\n",
       " 'focus',\n",
       " 'unfortunately',\n",
       " 'followed',\n",
       " 'curtis',\n",
       " 'magic',\n",
       " 'sounded',\n",
       " 'becomes',\n",
       " 'animal',\n",
       " 'expect',\n",
       " 'warm',\n",
       " 'wrote',\n",
       " 'odd',\n",
       " 'pepper',\n",
       " 'individual',\n",
       " 'statement',\n",
       " 'based',\n",
       " 'au',\n",
       " 'massive',\n",
       " 'fade',\n",
       " 'hill',\n",
       " 'turned',\n",
       " 'moving',\n",
       " 'forward',\n",
       " 'indeed',\n",
       " 'sings',\n",
       " 'stay',\n",
       " 'river',\n",
       " 'inside',\n",
       " 'diamond',\n",
       " 'manages',\n",
       " 'no',\n",
       " 'serious',\n",
       " 'rapping',\n",
       " 'mccartney',\n",
       " 'fantasy',\n",
       " 'percussion',\n",
       " 'nowhere',\n",
       " 'tour',\n",
       " 'seemed',\n",
       " 'repetitive',\n",
       " 'earth',\n",
       " 'killer',\n",
       " 'influential',\n",
       " 'forget',\n",
       " 'plant',\n",
       " 'drive',\n",
       " 'kill',\n",
       " 'latter',\n",
       " 'mainstream',\n",
       " 'book',\n",
       " 'outside',\n",
       " 'small',\n",
       " 'tout',\n",
       " 'variety',\n",
       " 'bruce',\n",
       " 'praise',\n",
       " 'sex',\n",
       " 'technical',\n",
       " 'synths',\n",
       " 'l',\n",
       " 'carry',\n",
       " 'ha',\n",
       " 'chance',\n",
       " 'perfection',\n",
       " 'delivery',\n",
       " 'stick',\n",
       " 'mentioned',\n",
       " 'somewhere',\n",
       " 'actual',\n",
       " 'guitarist',\n",
       " 'saw',\n",
       " 'running',\n",
       " 'recommend',\n",
       " 'producer',\n",
       " 'eventually',\n",
       " 'order',\n",
       " 'ocean',\n",
       " 'self',\n",
       " 'vinyl',\n",
       " 'organ',\n",
       " 'attempt',\n",
       " 'doom',\n",
       " 'muy',\n",
       " 'slowly',\n",
       " 'tried',\n",
       " 'loveless',\n",
       " 'sea',\n",
       " 'brain',\n",
       " 'born',\n",
       " 'evil',\n",
       " 'trip',\n",
       " 'lady',\n",
       " 'do',\n",
       " 'session',\n",
       " 'okay',\n",
       " 'front',\n",
       " 'pleasure',\n",
       " 'closing',\n",
       " 'echo',\n",
       " 'co',\n",
       " 'hype',\n",
       " 'st',\n",
       " 'admit',\n",
       " 'interlude',\n",
       " 'atmospheric',\n",
       " 'pixy',\n",
       " 'dynamic',\n",
       " 'content',\n",
       " 'century',\n",
       " 'eno',\n",
       " 'rate',\n",
       " 'cancin',\n",
       " 'detail',\n",
       " 'drummer',\n",
       " 'pain',\n",
       " 'grand',\n",
       " 'lie',\n",
       " 'higher',\n",
       " 'realize',\n",
       " 'mingus',\n",
       " 'considering',\n",
       " 'influenced',\n",
       " 'abbey',\n",
       " 'michael',\n",
       " 'transition',\n",
       " 'filled',\n",
       " 'van',\n",
       " 'green',\n",
       " 'mejor',\n",
       " 'comparison',\n",
       " 'artistic',\n",
       " 'needed',\n",
       " 'exception',\n",
       " 'ian',\n",
       " 'subject',\n",
       " 'appeal',\n",
       " 'bar',\n",
       " 'force',\n",
       " 'fusion',\n",
       " 'impossible',\n",
       " 'rocker',\n",
       " 'mine',\n",
       " 'angel',\n",
       " 'steve',\n",
       " 'brother',\n",
       " 'smooth',\n",
       " 'pull',\n",
       " 'ahead',\n",
       " 'rubber',\n",
       " 'backing',\n",
       " 'leaf',\n",
       " 'creating',\n",
       " 'generation',\n",
       " 'otherwise',\n",
       " 'super',\n",
       " 'kanyes',\n",
       " 'reminds',\n",
       " 'algo',\n",
       " 'as',\n",
       " ...]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.index_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54523011",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_w2v \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: document_vector(x\u001b[38;5;241m.\u001b[39msplit()))\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_w2v \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCleaned_Review\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: document_vector(x\u001b[38;5;241m.\u001b[39msplit()))\n",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m, in \u001b[0;36mdocument_vector\u001b[1;34m(word_list)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdocument_vector\u001b[39m(word_list):\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m# Remove out-of-vocabulary words\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m     word_list \u001b[38;5;241m=\u001b[39m [word \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m word_list \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m w2v_model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key]\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(word_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m100\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_w2v = data['Cleaned_Review'].apply(lambda x: document_vector(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_w2v\n",
    "#save in a csv\n",
    "# Convert the Series of numpy arrays to a DataFrame\n",
    "X_w2v_df = X_w2v.apply(pd.Series)\n",
    "# Optionally, add the index or an identifier if needed\n",
    "X_w2v_df.to_csv('./dataset/X_w2v_vectors.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99568a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# X_train_w2v, X_test_w2v, y_train, y_test = train_test_split(X_w2v, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f062",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(alpha=1.0),\n",
    "    # 'RandomForestRegressor':RandomForestRegressor(),\n",
    "    # 'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    # 'SVR':SVR(),\n",
    "    # 'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    # 'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    # 'XGBRegressor':XGBRegressor(),\n",
    "    # 'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "695a124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "metrics_list = []\n",
    "\n",
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e38034c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.549724</td>\n",
       "      <td>0.741434</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.555106</td>\n",
       "      <td>0.186065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.501959</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.181037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0  LinearRegression  0.549724  0.741434  0.266183  0.555106  0.186065\n",
       "1             Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2             Ridge  0.501959  0.708491  0.329944  0.525581  0.181037"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe44e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'RandomForestRegressor':RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'GradientBoostingRegressor':GradientBoostingRegressor(n_estimators=100, random_state=42, n_jobs=-1),\n",
    "    # 'SVR':SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d56853",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c6d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ab644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34d9a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.549724</td>\n",
       "      <td>0.741434</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.555106</td>\n",
       "      <td>0.186065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.501959</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.181037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.874224</td>\n",
       "      <td>0.934999</td>\n",
       "      <td>-0.166985</td>\n",
       "      <td>0.694065</td>\n",
       "      <td>0.245467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.096813</td>\n",
       "      <td>1.047289</td>\n",
       "      <td>-0.464116</td>\n",
       "      <td>0.713785</td>\n",
       "      <td>0.238664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0       LinearRegression  0.549724  0.741434  0.266183  0.555106  0.186065\n",
       "1                  Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2                  Ridge  0.501959  0.708491  0.329944  0.525581  0.181037\n",
       "3    KNeighborsRegressor  0.874224  0.934999 -0.166985  0.694065  0.245467\n",
       "4  DecisionTreeRegressor  1.096813  1.047289 -0.464116  0.713785  0.238664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'XGBRegressor':XGBRegressor(),\n",
    "    'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test,y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1248\u001b[0m     params,\n\u001b[0;32m   1249\u001b[0m     train_dmatrix,\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1251\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1252\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1253\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1254\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1255\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1256\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1257\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1258\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1259\u001b[0m )\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     _check_call(\n\u001b[1;32m-> 2247\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2249\u001b[0m         )\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68306cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5019594967014778\n",
      "R2: 0.3299435449804736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a9a2e5f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter review: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Clean the review text\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m clean_data \u001b[38;5;241m=\u001b[39m preprocess_text(text)  \u001b[38;5;66;03m# This should return a cleaned string\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Vectorize using the already trained vectorizer (do NOT use fit_transform)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m X \u001b[38;5;241m=\u001b[39m tfidf_vectorizer\u001b[38;5;241m.\u001b[39mtransform([clean_data])  \u001b[38;5;66;03m# Wrap in a list to avoid error\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'preprocess_text' is not defined"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "text = input(\"Enter review: \")\n",
    "\n",
    "# Clean the review text\n",
    "clean_data = preprocess_text(text)  # This should return a cleaned string\n",
    "\n",
    "# Vectorize using the already trained vectorizer (do NOT use fit_transform)\n",
    "X = tfidf_vectorizer.transform([clean_data])  # Wrap in a list to avoid error\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_rating = model.predict(X)\n",
    "\n",
    "# Output the result\n",
    "print(f\"The predicted rating for the review '{text}' is: {predicted_rating[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "df4b6dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enhanced Pipeline Performance:\n",
      "MSE: 0.5941\n",
      "MAE: 0.5827\n",
      "R2: 0.2069\n",
      "RMSE: 0.7708\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "\n",
    "# Enhanced pipeline with feature selection\n",
    "pipeline = make_pipeline(\n",
    "    StandardScaler(with_mean=False),  # Important for sparse matrices\n",
    "    SelectKBest(f_regression, k=5000),\n",
    "    GradientBoostingRegressor(n_estimators=200, learning_rate=0.05, random_state=42)\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "print(\"\\nEnhanced Pipeline Performance:\")\n",
    "print(f\"MSE: {mean_squared_error(y_test, y_pred):.4f}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, y_pred):.4f}\")\n",
    "print(f\"R2: {r2_score(y_test, y_pred):.4f}\")\n",
    "print(f\"RMSE: {np.sqrt(mean_squared_error(y_test, y_pred)):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
