{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af24d0",
   "metadata": {},
   "source": [
    "## Exploraty Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da38a85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating\n",
       "0  i think i actually under-rate ok computer if a...     5.0\n",
       "1  i get why radiohead rub a lot of people the wr...     5.0\n",
       "2  i would like to think i am good about not lett...     4.5\n",
       "3  there are radiohead devotees like there were o...     4.0\n",
       "4  i wrote a shining excellent review for this al...     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/music_album_reviews.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 80271\n",
      "Rating distribution:\n",
      "Rating\n",
      "5.0    29534\n",
      "4.5    17793\n",
      "4.0    14213\n",
      "3.5     7048\n",
      "3.0     4430\n",
      "2.5     2210\n",
      "2.0     1396\n",
      "1.5      640\n",
      "1.0      525\n",
      "0.5      398\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dataset size: {len(df)}\")\n",
    "print(f\"Rating distribution:\\n{df['Rating'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abb8eaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review      26\n",
       "Rating    2084\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f313865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop null values\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d4e121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function which tokenizes the text,lowercase the text, remove stopwords, and lemmatize the text \n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z\\s!?]', '', text)  # Keep !? for sentiment\n",
    "    words = word_tokenize(text)\n",
    "    stop_words = list(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Cleaned_Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i think i actually under-rate ok computer if a...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>think actually underrate ok computer anything ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i get why radiohead rub a lot of people the wr...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>get radiohead rub lot people wrong way lot peo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i would like to think i am good about not lett...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>would like think good letting wider critical w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>there are radiohead devotees like there were o...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>radiohead devotee like bowie devotee find unex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i wrote a shining excellent review for this al...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>wrote shining excellent review album browser w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  \\\n",
       "0  i think i actually under-rate ok computer if a...     5.0   \n",
       "1  i get why radiohead rub a lot of people the wr...     5.0   \n",
       "2  i would like to think i am good about not lett...     4.5   \n",
       "3  there are radiohead devotees like there were o...     4.0   \n",
       "4  i wrote a shining excellent review for this al...     5.0   \n",
       "\n",
       "                                      Cleaned_Review  \n",
       "0  think actually underrate ok computer anything ...  \n",
       "1  get radiohead rub lot people wrong way lot peo...  \n",
       "2  would like think good letting wider critical w...  \n",
       "3  radiohead devotee like bowie devotee find unex...  \n",
       "4  wrote shining excellent review album browser w...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Cleaned_Review'] = df['Review'].apply(preprocess_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b0f5a071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7734a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "321"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb80a854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove the empty strings in cleaned_review column\n",
    "df = df[df['Cleaned_Review'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0293cb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Cleaned_Review'] == '').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f3af1b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cleaned_csv \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./dataset/cleaned_music_reviews.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "cleaned_csv = df.to_csv('./dataset/cleaned_music_reviews.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6dc66420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review            0\n",
       "Rating            0\n",
       "Cleaned_Review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./dataset/cleaned_music_reviews.csv')\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54e8e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1,2),\n",
    "    max_df=0.8,\n",
    "    min_df=5,\n",
    ")\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(data['Cleaned_Review'])\n",
    "vocab = tfidf_vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99568a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Rating']\n",
    "# y.to_csv('./dataset/y.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f07667a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# X_dense = X.toarray()\n",
    "\n",
    "# # 3. Create a DataFrame\n",
    "# X_df = pd.DataFrame(X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcebbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_df.to_csv('./dataset/X.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38f062",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'LinearRegression':LinearRegression(),\n",
    "    'Lasso':Lasso(),\n",
    "    'Ridge':Ridge(),\n",
    "    # 'RandomForestRegressor':RandomForestRegressor(),\n",
    "    # 'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    # 'SVR':SVR(),\n",
    "    # 'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    # 'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "    # 'XGBRegressor':XGBRegressor(),\n",
    "    # 'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "695a124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,r2_score,mean_absolute_error,mean_absolute_percentage_error\n",
    "metrics_list = []\n",
    "\n",
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e38034c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.549724</td>\n",
       "      <td>0.741434</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.555106</td>\n",
       "      <td>0.186065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.501959</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.181037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0  LinearRegression  0.549724  0.741434  0.266183  0.555106  0.186065\n",
       "1             Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2             Ridge  0.501959  0.708491  0.329944  0.525581  0.181037"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fe44e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'RandomForestRegressor':RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor':GradientBoostingRegressor(),\n",
    "    'SVR':SVR()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7029e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4c6d0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNeighborsRegressor':KNeighborsRegressor(),\n",
    "    'DecisionTreeRegressor':DecisionTreeRegressor(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0ab644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c34d9a38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>R2</th>\n",
       "      <th>MAE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>0.549724</td>\n",
       "      <td>0.741434</td>\n",
       "      <td>0.266183</td>\n",
       "      <td>0.555106</td>\n",
       "      <td>0.186065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>0.749184</td>\n",
       "      <td>0.865554</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>0.672071</td>\n",
       "      <td>0.238454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>0.501959</td>\n",
       "      <td>0.708491</td>\n",
       "      <td>0.329944</td>\n",
       "      <td>0.525581</td>\n",
       "      <td>0.181037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsRegressor</td>\n",
       "      <td>0.874224</td>\n",
       "      <td>0.934999</td>\n",
       "      <td>-0.166985</td>\n",
       "      <td>0.694065</td>\n",
       "      <td>0.245467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.096813</td>\n",
       "      <td>1.047289</td>\n",
       "      <td>-0.464116</td>\n",
       "      <td>0.713785</td>\n",
       "      <td>0.238664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model       MSE      RMSE        R2       MAE      MAPE\n",
       "0       LinearRegression  0.549724  0.741434  0.266183  0.555106  0.186065\n",
       "1                  Lasso  0.749184  0.865554 -0.000071  0.672071  0.238454\n",
       "2                  Ridge  0.501959  0.708491  0.329944  0.525581  0.181037\n",
       "3    KNeighborsRegressor  0.874224  0.934999 -0.166985  0.694065  0.245467\n",
       "4  DecisionTreeRegressor  1.096813  1.047289 -0.464116  0.713785  0.238664"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8040d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'XGBRegressor':XGBRegressor(),\n",
    "    'LGBMRegressor':LGBMRegressor(),\n",
    "    # 'CatBoostRegressor':CatBoostRegressor()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m----> 2\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train,y_train)\n\u001b[0;32m      3\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      4\u001b[0m     mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test,y_pred)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m train(\n\u001b[0;32m   1248\u001b[0m     params,\n\u001b[0;32m   1249\u001b[0m     train_dmatrix,\n\u001b[0;32m   1250\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_num_boosting_rounds(),\n\u001b[0;32m   1251\u001b[0m     evals\u001b[38;5;241m=\u001b[39mevals,\n\u001b[0;32m   1252\u001b[0m     early_stopping_rounds\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mearly_stopping_rounds,\n\u001b[0;32m   1253\u001b[0m     evals_result\u001b[38;5;241m=\u001b[39mevals_result,\n\u001b[0;32m   1254\u001b[0m     obj\u001b[38;5;241m=\u001b[39mobj,\n\u001b[0;32m   1255\u001b[0m     custom_metric\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[0;32m   1256\u001b[0m     verbose_eval\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[0;32m   1257\u001b[0m     xgb_model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m   1258\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks,\n\u001b[0;32m   1259\u001b[0m )\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m bst\u001b[38;5;241m.\u001b[39mupdate(dtrain, iteration\u001b[38;5;241m=\u001b[39mi, fobj\u001b[38;5;241m=\u001b[39mobj)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zainab\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     _check_call(\n\u001b[1;32m-> 2247\u001b[0m         _LIB\u001b[38;5;241m.\u001b[39mXGBoosterUpdateOneIter(\n\u001b[0;32m   2248\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle, ctypes\u001b[38;5;241m.\u001b[39mc_int(iteration), dtrain\u001b[38;5;241m.\u001b[39mhandle\n\u001b[0;32m   2249\u001b[0m         )\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in models.values():\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test,y_pred)\n",
    "    mae = mean_absolute_error(y_test,y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_test,y_pred)\n",
    "    metrics_list.append({\n",
    "        'Model':model.__class__.__name__,\n",
    "        'MSE':mse,\n",
    "        'RMSE':rmse,\n",
    "        'R2':r2,\n",
    "        'MAE':mae,\n",
    "        'MAPE':mape})\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68306cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.5019594967014778\n",
      "R2: 0.3299435449804736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "model = Ridge()\n",
    "model.fit(X_train,y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test,y_pred)\n",
    "r2 = r2_score(y_test,y_pred)\n",
    "\n",
    "print(f\"MSE: {mse}\")\n",
    "print(f\"R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7a9a2e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted rating for the review '    \"Mediocre at best - nothing special\",' is: 2.44\n"
     ]
    }
   ],
   "source": [
    "# Get user input\n",
    "text = input(\"Enter review: \")\n",
    "\n",
    "# Clean the review text\n",
    "clean_data = preprocess_text(text)  # This should return a cleaned string\n",
    "\n",
    "# Vectorize using the already trained vectorizer (do NOT use fit_transform)\n",
    "X = tfidf_vectorizer.transform([clean_data])  # Wrap in a list to avoid error\n",
    "\n",
    "# Predict using the trained model\n",
    "predicted_rating = model.predict(X)\n",
    "\n",
    "# Output the result\n",
    "print(f\"The predicted rating for the review '{text}' is: {predicted_rating[0]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
